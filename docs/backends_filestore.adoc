= Ein Graphstore-Backend auf dem Dateisystem

Der Graphstore kann mit unterschiedlichsten Key-Value-Stores als Backend
betrieben werden. Dieses Dokument beschreibt ein Backend auf Basis des
Dateisystems.

== Vorteile des Dateisystems
Ich denke die meisten würden nicht sagen, dass das Dateisystem eine gute
Basis ist um eine Graphendatenbank zu implementieren (wobei das reine
Vermutung ist. Bisher hat niemand etwas derartiges zu mir gesagt). Es
gibt aber einige Vorzüge, die das Dateisystem hat:

* Auf jedem normalen Computer ist bereits eins installiert
* Es wird seit Jahrzehnten benutzt und weiterentwickelt. Man kann davon
  ausgehen, dass viele Optimierungen welche in Key-Value Stores
  eingebaut werden auch in Dateisystemen zu finden sind.
** Ein Dateisystem *ist* ein Key-Value Store. Es sollte daher nicht
   schwer sein die API später auf einen anderen KV-Store zu portieren.
* Es gibt eine Unmenge verschiedener Dateisystem Implementierungen.
  Wählt man das Richtige für den Anwendungsfall bekommt man
  Optimierungen und/oder zusätzliche Features
** Zusätzliche Features wären z.B. verteilte Dateisysteme welche viele
   Möglichkeiten bieten um die Availability zu steigern.
** Gleichzeitig werden das auch einige als ein Gegenargument aufführen
   können: Da es so viele verschiedene Implementierungen gibt (und diese
   für den Benutzer transparent sind) verlieren wir die Kontrolle über
   die eigentliche Implementierung und haben am Ende eventuell eine
   schlechte Performance nur weil der Benutzer ein schlecht geeignetes
   Dateisystem verwendet (oder es schlecht konfguriert ist)
* Es gibt unzählige Tools für das Dateisystem welche man bei der
  Entwicklung, Wartung und in unserem eigenen Prozess verwenden kann:
** Dateimanager und Editoren ermöglichen ein interaktives Untersuchen
   unseres Systems
** Tools wie `grep`,`sed`,`find` und `awk` erlauben eine sehr flexibele
   und doch schnelle Suche über das Gesamtsystem.
** Versionskontrollsysteme erlauben Synchronisiation von außen
   bereitszustellen. Wenn wir einen geschickten Diff Mechnismus
   bereitstellen können sie beinahe nahtlos eingefügt werden.
*** Das ist ein absolutes Killer Feature welches mit riesigem Aufwand
    verbunden wäre wenn wir es selbst implementieren wollten (was
    wir aber vielleicht eines Tages möchten :) ) aber gleichzeitig
    Anwendungsfälle und Möglichkeiten bietet die derzeit kaum
    (vielleicht kein?) allgemeines Datenbank System ermöglicht.
** etc (Tools die Funktionen für das Dateisystem bereitsstellen gibt es
   zu Hauf. Eventuell erlauben einige Anwendungen welche uns noch gar
   nicht bekannt sind)
* Es ist recht skalierbar

== Struktur für die Ablage der Daten
Zunächst beschäftigen wir uns mit der Strukturierung der Datenablage um zu sehen wie unsere Daten aussehen. Anschließend konzentieren wir uns auf die Funktionen um diese Dateien zu erzeugen und manipulieren.

Ich stelle mir folgende Baumstruktur vor:

[source]
.Dateibaumstruktur der Datenbank
----

db/--+
     +-nodes/--+
     |         +-<uuid>
     |         +-...
     +-edges/--+
     |         +-<hash string>
     |         +-...
     +-props/--+
     |         +-<hash string>
     |         +-...
     +-indexes/--+
     |           +-...
     +-config/--+
     |          +-...
     +-...
----

[%collapsible]
.Implementierungsdetails um die Dateibaumstruktur zu pflegen
====

Bei einer neuen Datenbank erzeugen wir zunächst all diese Ordner.

[[create_db_directories]]
[source, rust]
----
fs::create_dir_all(&path.join("nodes/"))?;
fs::create_dir_all(&path.join("edges/"))?;
fs::create_dir_all(&path.join("props/"))?;
fs::create_dir_all(&path.join("indexes/"))?;
----

Wird eine bestehende Datenbank geöffnet muss überprüft werden, ob die
entsprechenden Ordner vorhanden sind.

[[check_db_directories]]
[source, rust]
----
if !&path.join("nodes/").is_dir() ||
  !&path.join("edges/").is_dir() ||
  !&path.join("props/").is_dir() ||
  !&path.join("indexes/").is_dir() {
    return Err(FileStoreError::MalformedDB);
}
----

Falls die Struktur nicht eingehalten wurde geben wir einen Fehler aus.

[[errors]]
[source, rust]
----
#[error("wrongly formatted database at path TODO")]
MalformedDB,
----

====

Innerhalb dieser Ordner (oder der meisten dieser Ordner denn z.B. config enthält ja nur Beschreibungsdaten) werden die Datensätze als Dateien abgelegt. Der Dateiname ist dabei der Schlüssel mit dem man auf die Daten zugreift und der Dateiinhalt ist der Wert. Als Schlüssel wird entweder ein `Hash` oder eine `Uuid` verwendet.

Hash:: Ein https://en.wikipedia.org/wiki/Cryptographic_hash_function[Hash] ist die eindeutige Zusammenfassung des Inhalts als eine Zahl. Alles was einen `hash` als Schlüssel hat ist somit ein https://en.wikipedia.org/wiki/Content-addressable_storage[content addressable store] da mit dem Schlüssel der Inhalt fest verbunden ist. Der verwendete Hash Algorithmus kann über die Konfiguration festgelegt werden. Das hat ein paar Vorteile:
** Die Daten können nur entweder erstellt oder gelöscht werden aber nicht verändert. Daraus ergeben sich eine Menge Möglichkeiten für die Synchronisierung und Prüfung der Datenintegrität.
Uuid:: Eine https://en.wikipedia.org/wiki/Universally_unique_identifier[Uuid] ist eine eindeutige Id bei der nicht die Gefahr besteht, das zwei unterschiedliche Prozesse die gleiche id erstellen (nicht mal wenn die Prozesse auf unabhängigen und nicht miteinander kommunizierenden Computern ablaufen). Datensätze welche eine `uuid` als Schlüssel verwenden können modifiziert werden.

Wie wir später noch sehen werden hat diese Strukturierung Vorteile um die Daten gut <<sync, synchronisieren>> und effektiv durchsuchen zu können.

Um diese Keys umzusetzen verwenden wir die https://docs.rs/uuid[uuid] und https://docs.rs/sha2[sha2] crates. Für sie definieren wir eine Hilfsschnittstelle, um die Umwandlung in einen Datenbankschlüssel zu erlauben.

Als Schlüssel betrachten wir hier den zusammengefassten Dateinamen aus allen Ordnernamen unterhalb der hier aufgeführten Struktur und dem Dateinamen (ohne die Trennzeichen wie z.B `/`). Wie viele Ordner verwendet werden sollen und ob die Tiefe dynamisch angepasst werden soll hängt von der Konfiguration ab. Dadurch ist es möglich die Abfragegeschwindigkeiten zu optimieren je nachdem wie voll die Datenbank ist.

Dateinamen sind im Grunde Strings, weshalb wir unsere Hashes in diesem Fall als String definieren können.

[[structs]]
[source, rust]
----
type HashId = String;
----

Als Hash Funktion nutzen wir (vorerst) sha256. Dafür importieren wir die Digest traits.

[[imports]]
[source, rust]
----
use sha2::Digest;
----

=== Die einzelnen Datentypen
Nun wollen wir die Einzelheiten und Schemata der einzelnen Datentypen besprechen.

Die Dateiinhalte sind Key-Value Stores welche die Werte das Datensatzes enthalten. Man kann dafür z.B. Json, messagepack oder etwas anderes verwenden (theoretisch könnte man sogar wieder das Datesystem verwenden, da ein Ordner ja auch nichts anderes als ein Key-Value-Store ist). Das verwendete Dateiformat kann über die Konfiguration festgelegt werden (das Schema dagegen besprechen wir in den folgenden Abschnitten). Zu Beginn mag es nützlich sein Json zu verwenden, da es leicht zum Debuggen geeignet ist.

Um uns die Flexibilität zu erhalten verwenden wir zunächst https://serde.rs/[serde] zur Serialisierung. Dadurch lässt sich das Datenformat für unsere Datentypen leicht austauschen. Natürlich kann man als Properties (TODO link) beliebige Dateien und Formate abspeichern.

Zu Beginn nutzen wir json als Serialisierungsformat footnote:[Das gilt nur für unsere internen Datenstrukturen innerhalb der Datenbank. Jedes Schema kann völlig frei seine eigene Serialisierung wählen]. Dazu nutzen wir `serde_json`.

Wir verwenden die Schema Traits (TODO link) von gravity um die Datentypen zu definieren. Dadurch haben wir später die Möglichkeit zum validieren (TODO link) und optimieren (TODO link), was gerade bei Transaktionen (TODO link) von großem Nutzen ist.

[[imports]]
[source, rust]
----
use gravity::schema::SchemaElement;
----

=== Eigenschaften (properties)
Im Ordner `properties` können beliebige Daten gespeichert werden. Diese Dateien enthalten das, was man im Allgemeinen als die eigentlichen Nutzdaten betrachten würde.

In einem herkömmlichen Arbeitsprozess (also ohne Graphendatenbank) sind alle Dateien die man erzeugt und bearbeitet mit Properties gleichzusetzen. Und in einer SQL Datenbank entspräche der Inhalt aller Zeilen, die keine Primary- oder Foreign-Keys enthalten, den Properties.

Dementsprechend ist es sinnvoll für jede Anwendung ein eigenes Schema (TODO link) für die Properties zu entwerfen und benutzen (ähnlich wie man es bei einer SQL Datenbank auch tun würde).

Allerdings möchten wir, dass unsere Datenbank auch verwendbar ist, ohne das jeder zuerst ein Schema erdenken und anschließend die Datenbank mit diesem Schema gemeinsam kompilieren muss. Aus diesem Grund definieren wir ein sehr allgemeines Schema, welches beliebige Daten (wie bespielsweise Dateien auf dem Computer) aufnehmen kann. Seine sehr laxe Validierung erlaubt direkt mit der Datenbank zu arbeiten.

[[structs]]
[source, rust]
.Allgemeines Schema für beliebige Properties
----
#[derive(Debug, Clone)]
pub struct GenericProperty(Vec<u8>);

impl SchemaElement<HashId, SerialisationError> for GenericProperty
{
  fn get_key(&self) -> HashId {
    format!("{:X}", sha2::Sha256::digest(&self.0))
  }

  fn serialize(&self) -> Result<Vec<u8>, SerialisationError> {
    Ok(self.0.clone())
  }

  fn deserialize(data: &[u8]) -> Result<Self, SerialisationError>
  where
    Self: Sized,
  {
    Ok(GenericProperty(data.to_vec()))
  }
}

impl Property<String, SerialisationError> for GenericProperty {
  fn nested(&self) -> Vec<Self> { Vec::new() } // <1>
}
----
<1> Wir bilden keine Verweise der Dateien untereinander ab, da wir ja bei dieser allgemeinen Fassung des Schemas die Dateien selbst gar nicht auswerten.

Daten die man hier verwendet können beliebige Inhalte haben. Es wäre aber klug (wenn auch nicht erforderlich) zu versuchen nicht deterministische Daten wie Änderungszeitstempel (oder Zeitstempel allgemein) vor dem Abspeichern aus den Dateien zu entfernen. Tut man das nicht, kann der nicht-Determinismus die Synchronisiation stark belasten. Es wäre also gut zu überdenken ob man einen direkten Anwendungsfall für die Auswertung solcher veränderlichen Daten hat oder die Daten sich sehr selten verändern, bevor man sich entschließt nicht deterministische Daten abzuspeichern.

== Implementierung

Da wir alles aus dem Dateisystem auslesen müssen wir auch die
ensprechenden Traits importieren.

[[imports]]
[source, rust]
----
use std::fs;
----

=== CRUD Funktionen
Wir benötigen natürlich zunächst die allgemeinenen Funktionen für
eine Key Value Datenbank. Dafür implementieren wir die allgemeine
Schnittstelle.

[[kvstore_interface_implementations]]
[source, rust]
.CRUD Funktionen
----
impl KVStore<FileStoreError> for FsKvStore
{
  fn create_bucket(&mut self, key: &[u8]) -> Result<(), FileStoreError> {
    Ok(std::fs::create_dir_all(self.key_to_path(key))?)
  }

  fn delete_record(&mut self, key: &[u8]) -> Result<(), FileStoreError> {
    Ok(std::fs::remove_file(self.key_to_path(key))?)
  }

  fn store_record(&mut self, key: &[u8], value: &[u8]) -> Result<(), FileStoreError> {
    Ok(std::fs::write(self.key_to_path(key), value)?)
  }

  fn fetch_record(&self, key: &[u8]) -> Result<Vec<u8>, FileStoreError> {
    Ok(std::fs::read(self.key_to_path(key))?)
  }

  fn list_records(&self, key: &[u8]) -> Result<Vec<Vec<u8>>, FileStoreError> {
    let iter: Vec<Vec<u8>> = fs::read_dir(self.key_to_path(key))?.into_iter().filter_map(|entry| {
      match entry {
        Ok(entry) => Some(entry.file_name().into_encoded_bytes()),
        Err(_) => None,
      }
    }).collect();
    Ok(iter)
  }

  fn exists(&self, key: &[u8]) -> Result<bool, FileStoreError> {
    Ok(self.key_to_path(key).exists())
  }
}
----

Wir müssen zudem mögliche Fehler vom Dateisystem abfangen.

[[errors]]
[source, rust]
----
#[error("io error")]
Io { #[from] source: std::io::Error },
----

Zudem müssen die Keys in Pfade umgewandelt werden.

[[fs_store_functions]]
[source, rust]
----
fn key_to_path(&self, key: &[u8]) -> PathBuf {
  let path = Path::new(OsStr::from_bytes(key));
  PathBuf::from(self.base_path.join(path))
}
----

[[imports]]
[source, rust]
----
use gravity::KVStore;
use std::io::Error;
use std::ffi::OsStr;
use std::os::unix::ffi::OsStrExt;
----

=== Schema Schnittstellen für Knoten, Verbindungen und Eigenschaften
Unsere Datenbank erlaubt es ein Schema zu definieren. Damit das möglich ist müssen die einzelnen Elemente Schnittstellen bereitstellen.

[[imports]]
[source, rust]
----
use gravity::schema::Property;
----

=== Abfrage Sprache einlesen
Abfragen können in der verschiedensten Form formuliert werden. Wir verwenden die Zoe (TODO link) Sprache um unsere Abfragen zu definieren. Allerdings haben wir die Möglichkeit andere Sprachen zu nutzen und diese in eine gleichwertige Zoe Abfrage umzuwandeln. Dafür müssen wir zunächst die Sprache importieren.

[[imports]]
[source, rust]
----
use gravity::ql;
pub use gravity::kv_graph_store::SerialisationError;
----

Anschliessend definieren wir unseren eigenen Dialekt indem wir die grundlegenden Datentypen festlegen footnote:[Dieser Dialekt wird durch die Anwendung noch weiter verfeinert, sobald das Schema festgelegt wird].

[[structs]]
[source, rust]
----
type BasicQuery = ql::BasicQuery<uuid::Uuid, HashId, HashId, ql::ShellFilter, ql::ShellFilter>;
----

Wir gehen davon aus, dass die Abfragen als Json codiert übermittelt werden.

[[helper_functions]]
[source, rust]
----
pub fn to_query(data: &Vec<u8>) -> Result<BasicQuery, SerialisationError> {
  // TODO Verschiedene Query Sprachen über zweiten Parameter
  // TODO Internes Schema verwenden um Abfragen zu verbessern
  let query = serde_json::from_slice(data)?;

  Ok(query)
}
----

=== Dateiorganisation des Crates
Wie überall benötigt man einiges an Boilerplate-Code.

[source, rust, save]
.src/lib.rs
----
<<imports>>

<<traits|join="\n\n">>

<<structs|join="\n\n">>

<<interface_implementations|join="\n\n">>

<<helper_functions|join="\n\n">>

----

Die wichtigste Struktur ist natürlich der Store selbst.

[[structs]]
[source, rust]
----
pub struct FsKvStore {
  <<fs_store_vars>>
}

<<kvstore_interface_implementations|join="\n\n">>

impl FsKvStore {
  <<fs_store_functions|join="\n\n">>
}
----

Bevor wir Abfragen auf unserer Datenbank ausführen können müssen wir erst einmal wissen wo sie ist. Dazu speichern wir den Pfad als interne Variable ab.

[[imports]]
[source, rust]
----
use std::path::{Path, PathBuf};
----

[[fs_store_vars]]
[source, rust]
----
base_path: PathBuf,
----

Um eine bestehende Datenbank zu benutzen legen wir eine entsprechende Funktion an. Zunächst wird überprüft, ob die Dateistruktur im Ordner der Datenbank korrekt ist.

[[fs_store_functions]]
[source, rust]
----
pub fn open(path: &Path) -> Result<Self, FileStoreError> {
  if !path.is_dir() {
    return Err(FileStoreError::MalformedDB);
  }
  <<check_db_directories>>

  Ok(FsKvStore {
    base_path: path.to_path_buf(),
  })
}
----

Wenn noch gar keine Datenbank existiert müssen wir sie zunächst initialisieren.

[[fs_store_functions]]
[source, rust]
----
pub fn init(path: &Path) -> Result<Self, FileStoreError> {
  if !path.is_dir() {
    if path.exists() {
      return Err(FileStoreError::MalformedDB);
    } else {
      fs::create_dir_all(&path)?;
    }
  }

  <<create_db_directories>>

  Ok(FsKvStore {
    base_path: path.to_path_buf(),
  })
}
----

==== Fehlerbehandlung
Wir verwenden den https://docs.rs/thiserror/1.0.26/thiserror/[thiserror] crate um die Fehlerbehandlung zu implementieren.

[[imports]]
[source, rust]
----
use thiserror::Error;
----

[[structs]]
[source, rust]
----
#[derive(Error, Debug)]
pub enum FileStoreError {
  <<errors>>
}
----

== Cmd-Tools
Wir nutzen einige Tools um die Datenbank über die Kommandozeile zu manipulieren.

Die Tools, die wir hier bereitstellen, sind dazu gedacht die Datenbank sofort mit unvalidierten Daten nutzen zu können. Es existiert also kein auf den Anwendungsfall zugeschnittenes Schema. Um ein Schema zu verwenden, wird man sehr ähnliche Tools brauchen. Deshalb legen wir uns eine Bibliothek mit Hilfsfunktionen an.

[[imports]]
[source, rust]
----
pub mod cli_helpers;
----

[[tool_imports]]
[source, rust]
----
use gravitydb_filestore::cli_helpers;
----

[source, rust, save]
.src/cli_helpers.rs
----
<<util_imports>>

<<tool_helper_functions|join="\n\n">>

<<cli_template_functions|join="\n\n">>
----

Wir stellen dabei ein Programm-Template bereit, welches alle wichtigen db Funktionen über Sub-Kommandos bereitstellt footnote:[Diesen Style von Kommandozeilen Parametern kennt man vielleicht von Tools wie git].

[[cli_template_functions]]
[source, rust]
----
pub fn db_cmds<T>() -> Result<()>
where
  T: Property<HashId, SerialisationError> + 'static + std::clone::Clone + mlua::UserData,
{
  <<cli_parse_cmd_options>>

  use CmdOpts::*;
  match opt.cmd {
    <<run_cli_cmds>>
  }

  Ok(())
}

fn open<T>(path: &Path) -> Result<KvGraphStore<T, FsKvStore, FileStoreError>, FileStoreError>
where
  T: Property<HashId, SerialisationError> + 'static + std::clone::Clone + mlua::UserData,
{
  let kv = FsKvStore::open(path)?;
  Ok(KvGraphStore::from_kv(kv))
}

fn init<T>(path: &Path) -> Result<KvGraphStore<T, FsKvStore, FileStoreError>, FileStoreError>
where
  T: Property<HashId, SerialisationError> + 'static + std::clone::Clone + mlua::UserData,
{
  let kv = FsKvStore::init(path)?;
  Ok(KvGraphStore::from_kv(kv))
}
----

[source, rust, save]
.src/bin/gravitydb.rs
----
<<tool_imports>>

fn main() -> Result<()> {
  cli_helpers::db_cmds::<gravitydb_filestore::GenericProperty>()
}
----

=== create_node
Wir benötigen ein Programm um neue Knoten zu erzeugen.

[[cmd_options]]
[source, rust]
----
/// create a new node
CreateNode {
  <<create_node_args>>
},
----

Normalerweise wird ein Argument mit der [[create_node_params]]`id` mit
übergeben. Dadurch kann man fest vorgeben, welche id man verwenden
möchte.

[[create_node_args]]
[source, rust]
----
#[structopt(long)]
id: Option<uuid::Uuid>,
----

Um allerdings nicht aus Versehen ständig neue Knoten zu erzeugen,
brechen wir ab, wenn eine Property bereits existiert und nicht explizit
angegeben wurde, dass man eine id erzeugen möchte. Dafür haben wir das
Flag [[create_node_params]]`create_id`.

[[create_node_args]]
[source, rust]
----
#[structopt(long)]
create_id: bool,
----

Manchmal wollen wir die bestehenden Eigenschaften eines Knotens
aktualisieren. Allerdings möchten wir verhindern dass das automatisch
geschieht (da sonst quasi ausversehen Daten verloren gehen könnten).
Wenn man einen bestehenden Knoten aktualisieren will muss man das flag
[[create_node_params]]`update` benutzen.

[[create_node_args]]
[source, rust]
----
#[structopt(short, long)]
update: bool,
----

Ein weiterer häufiger Anwendungsfall ist, dass man einen Datensatz
anlegen und anschließend mit ihm arbeiten möchte (z.B. um weitere
Datensätze zu verlinken). Ist der Datensatz bereits vorhanden möchte man
dennoch seine Id benutzen um weiter zu arbeiten.

Dafür ist es notwendig, dass bisher kein Knoten mit diesem Datensatz
(Properties) existiert (in diesem Fall legen wir ihn an) oder *exakt
ein* Knoten mit dem entsprechenden Datensatz vorhanden ist (in diesem
Fall gehen wir davon aus, dass das der Datensatz ist, den wir angelegt
hätten. Wenn mehr Datensätze vorhanden sind, wissen wir nicht welchen
Knoten wir verwenden müssen. Für diesen Anwendungsfall stellen wir die
Option [[create_node_params]]`get_or_create` auf der Kommandozeile zur
Verfügung.

[[create_node_args]]
[source, rust]
----
#[structopt(short, long)]
get_or_create: bool,
----

[[util_imports]]
[source, rust]
----
use gravity::schema::{SchemaElement, Property};
use crate::{FileStoreError, FsKvStore, HashId};
use anyhow::bail;
----

[[run_cli_cmds]]
[source, rust]
----
CreateNode {<<create_node_params|join=", ">>} => {
  if update && id.is_none() {
    bail!("to update a node you need to provide an id");
  }

  if create_id && get_or_create {
    bail!("you can either for creating an id or using an existing one if possible but not both");
  }

  let properties = read_input(opt.input)?;
  let properties: T = SchemaElement::deserialize(&properties)?;
  let id = match id {
    Some(id) => id,
    None => {
      let hash = properties.get_key();
      if opt
        .db_path
        .join("props/")
        .join(&hash)
        .exists()
      {
        if create_id {
          uuid::Uuid::new_v4()
        } else if get_or_create {
          let index_path = opt.db_path.join("indexes/").join(hash + "/");
          let mut nodes: Vec<uuid::Uuid> = std::fs::read_dir(&index_path)?.into_iter()
            .filter(|entry| {
              match entry {
                Ok(entry) => {
                  let reference = entry
                    .file_name()
                    .into_string()
                    .unwrap();
                  let (prefix, _reference) = reference
                    .split_once("_")
                    .unwrap();
                  if prefix == "nodes" {
                    true
                  } else {
                    false
                  }
                }
                Err(_) => false
              }
            })
            .take(2)
            .map(|entry| {
              let entry = entry.unwrap();
              let reference = entry
                .file_name()
                .into_string()
                .unwrap();
              let (_prefix, reference) = reference
                .split_once("_")
                .unwrap();
              uuid::Uuid::parse_str(reference).unwrap()
            })
            .collect();
          if nodes.len() == 1 {
            nodes.pop().unwrap()
          } else {
            bail!("There are several nodes with the same properties. Can't deside which one to use. Please use `--id` to specify the exact node");
          }
        } else {
          bail!("node allready exists. Please use `--create-id` to create a node with equal data anyway");
        }
      } else {
        uuid::Uuid::new_v4()
      }
    }
  };

  let mut db = open(&opt.db_path)?;
  if !update {
    db.create_node(id, &properties)?;
  } else {
    db.update_node(id, &properties)?;
  }

  println!("{}", id); // TODO opt.output, opt.output_fmt
}
----

=== delete_node
Dieses Tool erlaubt einen Knoten aus der Datenbank zu löschen.

[[cmd_options]]
[source, rust]
----
/// delete a node
DeleteNode {
  <<delete_node_args>>
},
----

Dazu übergeben wir die uuid des Knotens.

[[delete_node_args]]
[source, rust]
----
#[structopt(long)]
id: uuid::Uuid,
----

[[run_cli_cmds]]
[source, rust]
----
DeleteNode {id} => {
  let mut db = open::<T>(&opt.db_path)?;
  db.delete_node(id)?;
  log::info!("deleted node {}", id);
}
----

=== create_edge
Mit diesem Befehl können wir Verbindungen zwischen zwei Knoten schaffen.

[[cmd_options]]
[source, rust]
----
/// create a new edge
CreateEdge {
  <<create_edge_args>>
},
----

Alle Verbindungen sind immer gerichtet. Wir übergeben die id der Knoten `--in` und `--out`.

[[create_edge_args]]
[source, rust]
----
#[structopt(long="in")]
n1: uuid::Uuid,
#[structopt(long="out")]
n2: uuid::Uuid,
----

[[run_cli_cmds]]
[source, rust]
----
CreateEdge { n1, n2 } => {
  let properties = read_input(opt.input)?;
  let properties: T = SchemaElement::deserialize(&properties)?;

  let mut db = open(&opt.db_path)?;
  let id = db.create_edge(n1, n2, &properties)?;

  println!("{}", id); // TODO opt.output, opt.output_fmt
}
----

=== delete_edge

=== create_property

TODO Flag List connected properties

=== delete_property

TODO Flag Don't delete from cache
TODO Flag Don't delete connected properties from cache

=== property_id
Diese Funktion ist vor allem für Schema Implementierungen wichtig. Hier kann man Daten übergeben und die Funktion gibt die vom Schema erzeugte Id zurück. Wenn das Schema die Daten als ungültig identifiziert wird mit einer Fehlermeldung abgebrochen.

[[cmd_options]]
[source, rust]
----
/// calculate property id from content
PropertyId,
----

[[run_cli_cmds]]
[source, rust]
----
PropertyId => {
  let properties = read_input(opt.input)?;
  let properties: T = SchemaElement::deserialize(&properties)?;
  let hash = properties.get_key();

  println!("{}", hash); // TODO opt.output, opt.output_fmt
}
----

=== property_blob
Diese Funktion ist ebenfalls vor allem für Schema Implementierungen wichtig. Hier kann man Daten übergeben und die Funktion gibt den vom Schema erzeugten Datenstrom (Blob) zurück. Wenn das Schema die Daten als ungültig identifiziert wird mit einer Fehlermeldung abgebrochen.

[[cmd_options]]
[source, rust]
----
/// create property storage blob from content
PropertyBlob,
----

[[run_cli_cmds]]
[source, rust]
----
PropertyBlob => {
  let properties = read_input(opt.input)?;
  let properties: T = SchemaElement::deserialize(&properties)?;

  io::stdout().write_all(&SchemaElement::serialize(&properties)?)?;
}
----

Um so direkt schreiben zu können, müssen wir zunächst das `Write` Trait importieren.

[[util_imports]]
[source, rust]
----
use std::io::{self, Write};
----

=== query_db
Gibt einen Filter auf die aktuelle Datenbank in der Abfragesprache Zoe (TODO link) zurück.

[[cmd_options]]
[source, rust]
----
/// run a query on the database
QueryDb,
----

TODO Verschiedene Query Sprachen
Zunächst lesen wir die Abfrage ein und dann interpretieren wir sie.

[[run_cli_cmds]]
[source, rust]
----
QueryDb => {
  let query = read_input(opt.input)?;
  let query = crate::to_query(&query)?;

  let db = open::<T>(&opt.db_path)?;
  let result = db.query(query)?;

  <<get_connected_data>>

  // TODO verschiedene output formate
  println!("{}", serde_json::to_string_pretty(&result)?); // TODO wenn kein Terminal sondern eine pipe verwendet wird kann man kompakteres json ausgeben.

  // TODO Umschliessende Huelle? Alle miteinander verbundenen Edges und Vertices?
}
----

=== repl
Erlaubt die interaktive Manipulation der Datenbank mit einer lua repl.

[[cmd_options]]
[source, rust]
----
/// lua repl for the database
Repl,
----

Der Ablauf ist wie bei jeder anderen repl auch:

* Wir lesen das Script soweit ein, wie möglich
* Dann für wir das eingelesene Statement des Scripts aus
** Kommt es zu Fehlern untersuchen wir ob das Script noch nicht
   vollständig ist, oder ob wir die Verarbeitung abbrechen müssen.
* Wir formatieren die Ausgabe und geben sie für den Benutzer aus.
* Und dann kehren wir zum Anfang zurück (lesen das nächste Statement des
  Scripts ein).

[[run_cli_cmds]]
[source, rust]
----
Repl => {
  use mlua::{Error, Lua, MultiValue};
  use rustyline::Editor;

  let lua = Lua::new();
  let mut editor = Editor::<()>::new().expect("Failed to make rustyline editor");

  <<init_lua_environment>>

  loop {
    let mut prompt = "> ";
    let mut line = String::new();

    loop {
      let input = editor.readline(prompt)?;
      line.push_str(&input);

      match lua.load(&line).eval::<MultiValue>() {
        Ok(values) => {
          editor.add_history_entry(line);
          println!(
            "{}",
            values
              .iter()
              .map(|value| format!("{:?}", value))
              .collect::<Vec<_>>()
              .join("\t")
          );
          break;
        }
        Err(Error::SyntaxError {
          incomplete_input: true,
          ..
        }) => {
          // continue reading input and append it to `line`
          line.push_str("\n"); // separate input lines
          prompt = ">> ";
        }
        Err(e) => {
          eprintln!("error: {}", e);
          break;
        }
      }
    }
  }
}
----

Damit man mit der Repl auch etwas anfangen kann, muss sie auch
Funktionen bieten um die Datenbank zu manipulieren. Dazu binden wir den
`FsStore` Typ in unsere Lua Umgebung ein:

[[todo_interface_implementations]]
[source, rust]
----
impl<P> mlua::UserData for FsStore<P>
where
  P: Property<HashId, Error> + mlua::UserData + std::clone::Clone + 'static,
{
  fn add_methods<'lua, M: mlua::UserDataMethods<'lua, Self>>(methods: &mut M) {
    use mlua::prelude::LuaError;

    methods.add_method_mut("create_node", |_, db, props: P| {
      let id = uuid::Uuid::new_v4();
      match db.create_node(id, &props) {
        Ok(_) => Ok(()),
        Err(e) => Err(LuaError::external(e))
      }
    });
  }
}
----

[[interface_implementations]]
[source, rust]
----
impl mlua::UserData for GenericProperty {}
----

Und wir benötigen einige Constructor Funktionen um die Datenbank
verfügbar zu machen.

[[init_lua_environment]]
[source, rust]
----
let globals = lua.globals();
let db_open = lua.create_function(|_, path: String| {
  use mlua::prelude::LuaError;
  use std::sync::Arc;

  let path = crate::Path::new(&path);
  match open::<T>(&path) {
    Ok(db) => Ok(db),
    Err(e) => Err(LuaError::ExternalError(Arc::new(e))),
  }
})?;
globals.set("db_open", db_open)?;
----

Zudem laden wir die Funktionen der Abfragesprache Zoe (TODO link) in
unsere Lua Umgebung.

[[init_lua_environment]]
[source, rust]
----
ql::init_lua::<String, HashId, HashId, String, String>(&lua)?; // <1>
----
<1> Die generischen Parameter besetzen wir mit den in der Db
    hardverdrahteten Id Typen

[[util_imports]]
[source, rust]
----
use gravity::{ql, GraphStore};
----

=== result_outer_hull
Das Ergebnis unserer Abfrage ist eine Liste mit Knoten, Verbindungen und weiteren Variablen. Oft möchten wir das weiter ausweiten, indem wir alle Verbindungen zwischen den Knoten ebenfalls anzeigen möchten.

TODO

=== result_inner_hull
Ebenso wie eine umschließende Hülle interessiert uns manchmal eine innere Hülle, bei der wir alle Verbindungen entfernen, die nicht zwischen zwei Knoten der Ergebnismenge liegen.

TODO

=== result_data
Unsere Ergebnisse sind im allgemeinen nur die Ids von Knoten und
Verbindungen aber für die Verarbeitung (und vor allem Darstellung)
interessieren uns viel mehr die Eigenschaften. Mit diesem Befehl
können wir eine Ergebnissmenge nehmen und mit den dazugehörigen Daten
anreichern.

[[cmd_options]]
[source, rust]
----
/// get property data for query result
ResultData,
----

TODO

[[run_cli_cmds]]
[source, rust]
----
ResultData => {
  let data = read_input(opt.input)?;
  //let mut data: crate::ql::QueryResult = serde_json::from_slice(&data)?;

  let db = open::<T>(&opt.db_path)?;
  //TODO Über die db die Variablen im mit den Properties füllen

  // TODO verschiedene output formate
  println!("{}", serde_json::to_string_pretty(&data)?); // TODO wenn kein Terminal sondern eine pipe verwendet wird kann man kompakteres json ausgeben.
}
----


=== db_info
Gibt Informationen über die Datenbank als Json Format aus

* Number of Nodes
* Number of Edges
* Schema Info

=== db_init
Zu Beginn möchte man die Datenbank erstmal initialisieren. Dazu
verwenden wir den Befehl `init`.

[[cmd_options]]
[source, rust]
----
/// initialize a new database
Init,
----

[[run_cli_cmds]]
[source, rust]
----
Init => {
  init::<T>(&opt.db_path)?;
}
----

=== doctor
TODO Dieser Befehl überprüft, ob die Datenbank valid ist und listet Fehler auf.

TODO Fehler im Datei-Baum
TODO Fehler in der Schema Validierung
TODO Fehler in der Schema Validierung der Historie

=== Allgemeines
Natürlich benötigen wir in allen Tools den File Store.

[[util_imports]]
[source, rust]
----
use gravity::kv_graph_store::{KvGraphStore, SerialisationError};
----

==== Allgemeingültige Kommandozeilen Parameter
Einige Kommandozeilenparameter sind für alle tools nützlich. Wir
verwenden den https://docs.rs/structopt/[structopt] crate als basis um
die Eingabe zu parsen.

[[util_imports]]
[source, rust]
----
use std::path::{Path, PathBuf};
use structopt::StructOpt;
----

[[cli_parse_cmd_options]]
[source, rust]
----
#[derive(StructOpt)]
pub struct Opt {
  <<basic_tool_args>>
  #[structopt(subcommand)]
  cmd: CmdOpts,
}

#[derive(StructOpt)]
pub enum CmdOpts {
  <<cmd_options>>
}

let opt = Opt::from_args();
simple_logger::init_with_level(opt.verbosity)?;
----

Es muss immer angegeben werden, wo sich die Datenbank überhaupt
befindet. Falls nichts angegeben wird gehen wir davon aus, dass sie sich
im Unterordner `db` des aktuellen Ordners befindet.

[[basic_tool_args]]
[source, rust]
----
#[structopt(parse(from_os_str), long)]
#[structopt(default_value = "./db")]
db_path: PathBuf,
----

Normalerweise gibt es eine Eingabedatei die wir einlesen. Wird sie
nicht angegeben geht das Programm davon aus, dass die Daten von `stdin`
eingelesen werden.

[[basic_tool_args]]
[source, rust]
----
#[structopt(parse(from_os_str), long, short)]
input: Option<PathBuf>,
----

Genauso ist es mit der Ausgabedatei. Wird sie nicht angegeben, wird auf
`stdout` ausgegeben.

[[basic_tool_args]]
[source, rust]
----
#[structopt(parse(from_os_str), long, short)]
output: Option<PathBuf>,
----

Wir benutzen ein Hilfsfunktion um entweder die Daten aus einer Datei zu
lesen oder vom `stdin`.

[[util_imports]]
[source, rust]
----
use std::io::Read;
----

[[tool_helper_functions]]
[source, rust]
----
pub fn read_input(input: Option<PathBuf>) -> Result<Vec<u8>> {
  let data = match input {
    Some(path) => std::fs::read(path)?,
    None => {
      let mut data = Vec::new();
      std::io::stdin().read_to_end(&mut data)?;
      data
    }
  };
  Ok(data)
}
----

TODO Input Format
TODO Output Format
TODO Output File (Default stdout)

Wir wollen logging Informationen über die Kommandozeile anfordern. Je
öfter wir das Flag `v` angeben, desto mehr Daten werden angezeigt.

[[basic_tool_args]]
[source, rust]
----
#[structopt(parse(from_occurrences = log_level), short)]
verbosity: log::Level,
----

[[tool_helper_functions]]
[source, rust]
----
pub fn log_level(level: u64) -> log::Level {
  use log::Level::*;
  match level {
    0 => Warn,
    1 => Info,
    2 => Debug,
    _ => Trace,
  }
}
----

TODO Version information

==== Fehlerbehandlung
Bei den Kommandozeilen Tools möchten wir alle Fehler abfangen. Dazu
verwenden wir die https://docs.rs/anyhow[anyhow] Bibliothek.

[[tool_imports]]
[source, rust]
----
use anyhow::Result;
----

[[util_imports]]
[source, rust]
.Bei den util Funktionen verwenden
----
use anyhow::Result;
----
