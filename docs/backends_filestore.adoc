= Ein Graphstore-Backend auf dem Dateisystem

Der Graphstore kann mit unterschiedlichsten Key-Value-Stores als Backend
betrieben werden. Dieses Dokument beschreibt ein Backend auf Basis des
Dateisystems.

== Vorteile des Dateisystems
Ich denke die meisten würden nicht sagen, dass das Dateisystem eine gute
Basis ist um eine Graphendatenbank zu implementieren (wobei das reine
Vermutung ist. Bisher hat niemand etwas derartiges zu mir gesagt). Es
gibt aber einige Vorzüge, die das Dateisystem hat:

* Auf jedem normalen Computer ist bereits eins installiert
* Es wird seit Jahrzehnten benutzt und weiterentwickelt. Man kann davon
  ausgehen, dass viele Optimierungen welche in Key-Value Stores
  eingebaut werden auch in Dateisystemen zu finden sind.
** Ein Dateisystem *ist* ein Key-Value Store. Es sollte daher nicht
   schwer sein die API später auf einen anderen KV-Store zu portieren.
* Es gibt eine Unmenge verschiedener Dateisystem Implementierungen.
  Wählt man das Richtige für den Anwendungsfall bekommt man
  Optimierungen und/oder zusätzliche Features
** Zusätzliche Features wären z.B. verteilte Dateisysteme welche viele
   Möglichkeiten bieten um die Availability zu steigern.
** Gleichzeitig werden das auch einige als ein Gegenargument aufführen
   können: Da es so viele verschiedene Implementierungen gibt (und diese
   für den Benutzer transparent sind) verlieren wir die Kontrolle über
   die eigentliche Implementierung und haben am Ende eventuell eine
   schlechte Performance nur weil der Benutzer ein schlecht geeignetes
   Dateisystem verwendet (oder es schlecht konfguriert ist)
* Es gibt unzählige Tools für das Dateisystem welche man bei der
  Entwicklung, Wartung und in unserem eigenen Prozess verwenden kann:
** Dateimanager und Editoren ermöglichen ein interaktives Untersuchen
   unseres Systems
** Tools wie `grep`,`sed`,`find` und `awk` erlauben eine sehr flexibele
   und doch schnelle Suche über das Gesamtsystem.
** Versionskontrollsysteme erlauben Synchronisiation von außen
   bereitszustellen. Wenn wir einen geschickten Diff Mechnismus
   bereitstellen können sie beinahe nahtlos eingefügt werden.
*** Das ist ein absolutes Killer Feature welches mit riesigem Aufwand
    verbunden wäre wenn wir es selbst implementieren wollten (was
    wir aber vielleicht eines Tages möchten :) ) aber gleichzeitig
    Anwendungsfälle und Möglichkeiten bietet die derzeit kaum
    (vielleicht kein?) allgemeines Datenbank System ermöglicht.
** etc (Tools die Funktionen für das Dateisystem bereitsstellen gibt es
   zu Hauf. Eventuell erlauben einige Anwendungen welche uns noch gar
   nicht bekannt sind)
* Es ist recht skalierbar

== Struktur für die Ablage der Daten
Zunächst beschäftigen wir uns mit der Strukturierung der Datenablage um zu sehen wie unsere Daten aussehen. Anschließend konzentieren wir uns auf die Funktionen um diese Dateien zu erzeugen und manipulieren.

Ich stelle mir folgende Baumstruktur vor:

[source]
.Dateibaumstruktur der Datenbank
----

db/--+
     +-nodes/--+
     |         +-<uuid>
     |         +-...
     +-edges/--+
     |         +-<hash string>
     |         +-...
     +-props/--+
     |         +-<hash string>
     |         +-...
     +-indexes/--+
     |           +-...
     +-config/--+
     |          +-...
     +-...
----

[%collapsible]
.Implementierungsdetails um die Dateibaumstruktur zu pflegen
====

Bei einer neuen Datenbank erzeugen wir zunächst all diese Ordner.

[[create_db_directories]]
[source, rust]
----
fs::create_dir_all(&path.join("nodes/"))?;
fs::create_dir_all(&path.join("edges/"))?;
fs::create_dir_all(&path.join("props/"))?;
fs::create_dir_all(&path.join("indexes/"))?;
----

Wird eine bestehende Datenbank geöffnet muss überprüft werden, ob die
entsprechenden Ordner vorhanden sind.

[[check_db_directories]]
[source, rust]
----
if !&path.join("nodes/").is_dir() ||
  !&path.join("edges/").is_dir() ||
  !&path.join("props/").is_dir() ||
  !&path.join("indexes/").is_dir() {
    return Err(FileStoreError::MalformedDB);
}
----

Falls die Struktur nicht eingehalten wurde geben wir einen Fehler aus.

[[errors]]
[source, rust]
----
#[error("wrongly formatted database at path TODO")]
MalformedDB,
----

====

Innerhalb dieser Ordner (oder der meisten dieser Ordner denn z.B. config enthält ja nur Beschreibungsdaten) werden die Datensätze als Dateien abgelegt. Der Dateiname ist dabei der Schlüssel mit dem man auf die Daten zugreift und der Dateiinhalt ist der Wert. Als Schlüssel wird entweder ein `Hash` oder eine `Uuid` verwendet.

== Implementierung

Da wir alles aus dem Dateisystem auslesen müssen wir auch die
ensprechenden Traits importieren.

[[imports]]
[source, rust]
----
use std::fs;
----

=== CRUD Funktionen
Wir benötigen natürlich zunächst die allgemeinenen Funktionen für
eine Key Value Datenbank. Dafür implementieren wir die allgemeine
Schnittstelle.

[[kvstore_interface_implementations]]
[source, rust]
.CRUD Funktionen
----
impl KVStore<FileStoreError> for FsKvStore
{
  fn create_bucket(&mut self, key: &[u8]) -> Result<(), FileStoreError> {
    Ok(std::fs::create_dir_all(self.key_to_path(key))?)
  }

  fn delete_record(&mut self, key: &[u8]) -> Result<(), FileStoreError> {
    Ok(std::fs::remove_file(self.key_to_path(key))?)
  }

  fn store_record(&mut self, key: &[u8], value: &[u8]) -> Result<(), FileStoreError> {
    Ok(std::fs::write(self.key_to_path(key), value)?)
  }

  fn fetch_record(&self, key: &[u8]) -> Result<Vec<u8>, FileStoreError> {
    Ok(std::fs::read(self.key_to_path(key))?)
  }

  fn list_records(&self, key: &[u8]) -> Result<Vec<Vec<u8>>, FileStoreError> {
    let iter: Vec<Vec<u8>> = fs::read_dir(self.key_to_path(key))?.into_iter().filter_map(|entry| {
      match entry {
        Ok(entry) => Some(entry.file_name().into_encoded_bytes()),
        Err(_) => None,
      }
    }).collect();
    Ok(iter)
  }

  fn exists(&self, key: &[u8]) -> Result<bool, FileStoreError> {
    Ok(self.key_to_path(key).exists())
  }
}
----

Wir müssen zudem mögliche Fehler vom Dateisystem abfangen.

[[errors]]
[source, rust]
----
#[error("io error")]
Io { #[from] source: std::io::Error },
----

Zudem müssen die Keys in Pfade umgewandelt werden.

[[fs_store_functions]]
[source, rust]
----
fn key_to_path(&self, key: &[u8]) -> PathBuf {
  let path = Path::new(OsStr::from_bytes(key));
  PathBuf::from(self.base_path.join(path))
}
----

[[imports]]
[source, rust]
----
use gravitydb::KVStore;
use std::io::Error;
use std::ffi::OsStr;
use std::os::unix::ffi::OsStrExt;
----

=== Dateiorganisation des Crates
Wie überall benötigt man einiges an Boilerplate-Code.

[source, rust, save]
.src/lib.rs
----
<<imports>>

<<structs|join="\n\n">>

<<interface_implementations|join="\n\n">>
----

Die wichtigste Struktur ist natürlich der Store selbst.

[[structs]]
[source, rust]
----
pub struct FsKvStore {
  <<fs_store_vars>>
}

<<kvstore_interface_implementations|join="\n\n">>

impl FsKvStore {
  <<fs_store_functions|join="\n\n">>
}
----

Bevor wir Abfragen auf unserer Datenbank ausführen können müssen wir erst einmal wissen wo sie ist. Dazu speichern wir den Pfad als interne Variable ab.

[[imports]]
[source, rust]
----
use std::path::{Path, PathBuf};
----

[[fs_store_vars]]
[source, rust]
----
base_path: PathBuf,
----

Um eine bestehende Datenbank zu benutzen legen wir eine entsprechende Funktion an. Zunächst wird überprüft, ob die Dateistruktur im Ordner der Datenbank korrekt ist.

[[fs_store_functions]]
[source, rust]
----
pub fn open(path: &Path) -> Result<Self, FileStoreError> {
  if !path.is_dir() {
    return Err(FileStoreError::MalformedDB);
  }
  <<check_db_directories>>

  Ok(FsKvStore {
    base_path: path.to_path_buf(),
  })
}
----

Wenn noch gar keine Datenbank existiert müssen wir sie zunächst initialisieren.

[[fs_store_functions]]
[source, rust]
----
pub fn init(path: &Path) -> Result<Self, FileStoreError> {
  if !path.is_dir() {
    if path.exists() {
      return Err(FileStoreError::MalformedDB);
    } else {
      fs::create_dir_all(&path)?;
    }
  }

  <<create_db_directories>>

  Ok(FsKvStore {
    base_path: path.to_path_buf(),
  })
}
----

==== Fehlerbehandlung
Wir verwenden den https://docs.rs/thiserror/1.0.26/thiserror/[thiserror] crate um die Fehlerbehandlung zu implementieren.

[[imports]]
[source, rust]
----
use thiserror::Error;
----

[[structs]]
[source, rust]
----
#[derive(Error, Debug)]
pub enum FileStoreError {
  <<errors>>
}
----

== Cmd-Tools
Wir nutzen einige Tools um die Datenbank über die Kommandozeile zu manipulieren.

Die Tools, die wir hier bereitstellen, sind dazu gedacht die Datenbank sofort mit unvalidierten Daten nutzen zu können. Es existiert also kein auf den Anwendungsfall zugeschnittenes Schema. Um ein Schema zu verwenden, wird man sehr ähnliche Tools brauchen. Deshalb legen wir uns eine Bibliothek mit Hilfsfunktionen an.

[[imports]]
[source, rust]
----
pub mod cli_helpers;
----

[[tool_imports]]
[source, rust]
----
use gravitydb_filestore::cli_helpers;
----

[source, rust, save]
.src/cli_helpers.rs
----
<<util_imports>>

type HashId = String;

<<tool_helper_functions|join="\n\n">>

pub trait Prop: Property<HashId, SerialisationError> + 'static + std::clone::Clone + mlua::UserData {}
impl <T: Property<HashId, SerialisationError> + 'static + std::clone::Clone + mlua::UserData> Prop for T {}

<<cli_template_functions|join="\n\n">>

<<helper_structs|join="\n\n">>
----

Wir stellen dabei ein Programm-Template bereit, welches alle wichtigen db Funktionen über Sub-Kommandos bereitstellt footnote:[Diesen Style von Kommandozeilen Parametern kennt man vielleicht von Tools wie git].

[[cli_template_functions]]
[source, rust]
----
pub fn db_cmds<T>(<<customize_params|join=", ">>) -> Result<()>
where
  for<'lua> T: Prop + 'lua + mlua::FromLua,
{
  <<cli_parse_cmd_options>>

  use CmdOpts::*;
  match opt.cmd {
    <<run_cli_cmds>>
  }

  Ok(())
}

fn open<T>(path: &Path) -> Result<KvGraphStore<T, FsKvStore, FileStoreError>, FileStoreError>
where
  T: Prop,
{
  let kv = FsKvStore::open(path)?;
  Ok(KvGraphStore::from_kv(kv))
}

fn init<T>(path: &Path) -> Result<KvGraphStore<T, FsKvStore, FileStoreError>, FileStoreError>
where
  T: Prop,
{
  let kv = FsKvStore::init(path)?;
  Ok(KvGraphStore::from_kv(kv))
}
----

[source, rust, save]
.src/bin/gravitydb.rs
----
<<tool_imports>>

fn main() -> Result<()> {
  cli_helpers::db_cmds::<gravitydb::schema::GenericProperty>(init_nothing)
}

fn init_nothing(_ : &mlua::Lua) -> mlua::Result<()> {
  Ok(())
}
----

=== create_node
Wir benötigen ein Programm um neue Knoten zu erzeugen.

[[cmd_options]]
[source, rust]
----
/// create a new node
CreateNode {
  <<create_node_args>>
},
----

Normalerweise wird ein Argument mit der [[create_node_params]]`id` mit
übergeben. Dadurch kann man fest vorgeben, welche id man verwenden
möchte.

[[create_node_args]]
[source, rust]
----
#[clap(long)]
id: Option<uuid::Uuid>,
----

Um allerdings nicht aus Versehen ständig neue Knoten zu erzeugen,
brechen wir ab, wenn eine Property bereits existiert und nicht explizit
angegeben wurde, dass man eine id erzeugen möchte. Dafür haben wir das
Flag [[create_node_params]]`create_id`.

[[create_node_args]]
[source, rust]
----
#[clap(long)]
create_id: bool,
----

Manchmal wollen wir die bestehenden Eigenschaften eines Knotens
aktualisieren. Allerdings möchten wir verhindern dass das automatisch
geschieht (da sonst quasi ausversehen Daten verloren gehen könnten).
Wenn man einen bestehenden Knoten aktualisieren will muss man das flag
[[create_node_params]]`update` benutzen.

[[create_node_args]]
[source, rust]
----
#[clap(short, long)]
update: bool,
----

Ein weiterer häufiger Anwendungsfall ist, dass man einen Datensatz
anlegen und anschließend mit ihm arbeiten möchte (z.B. um weitere
Datensätze zu verlinken). Ist der Datensatz bereits vorhanden möchte man
dennoch seine Id benutzen um weiter zu arbeiten.

Dafür ist es notwendig, dass bisher kein Knoten mit diesem Datensatz
(Properties) existiert (in diesem Fall legen wir ihn an) oder *exakt
ein* Knoten mit dem entsprechenden Datensatz vorhanden ist (in diesem
Fall gehen wir davon aus, dass das der Datensatz ist, den wir angelegt
hätten. Wenn mehr Datensätze vorhanden sind, wissen wir nicht welchen
Knoten wir verwenden müssen. Für diesen Anwendungsfall stellen wir die
Option [[create_node_params]]`get_or_create` auf der Kommandozeile zur
Verfügung.

[[create_node_args]]
[source, rust]
----
#[clap(short, long)]
get_or_create: bool,
----

[[util_imports]]
[source, rust]
----
use gravitydb::schema::{SchemaElement, Property};
use crate::{FileStoreError, FsKvStore};
use anyhow::bail;
----

[[run_cli_cmds]]
[source, rust]
----
CreateNode {<<create_node_params|join=", ">>} => {
  if update && id.is_none() {
    bail!("to update a node you need to provide an id");
  }

  if create_id && get_or_create {
    bail!("you can either for creating an id or using an existing one if possible but not both");
  }

  let properties = read_input(opt.input)?;
  let properties: T = SchemaElement::deserialize(&properties)?;
  let id = match id {
    Some(id) => id,
    None => {
      let hash = properties.get_key();
      if opt
        .db_path
        .join("props/")
        .join(&hash)
        .exists()
      {
        if create_id {
          uuid::Uuid::new_v4()
        } else if get_or_create {
          let index_path = opt.db_path.join("indexes/").join(hash + "/");
          let mut nodes: Vec<uuid::Uuid> = std::fs::read_dir(&index_path)?.into_iter()
            .filter(|entry| {
              match entry {
                Ok(entry) => {
                  let reference = entry
                    .file_name()
                    .into_string()
                    .unwrap();
                  let (prefix, _reference) = reference
                    .split_once("_")
                    .unwrap();
                  if prefix == "nodes" {
                    true
                  } else {
                    false
                  }
                }
                Err(_) => false
              }
            })
            .take(2)
            .map(|entry| {
              let entry = entry.unwrap();
              let reference = entry
                .file_name()
                .into_string()
                .unwrap();
              let (_prefix, reference) = reference
                .split_once("_")
                .unwrap();
              uuid::Uuid::parse_str(reference).unwrap()
            })
            .collect();
          if nodes.len() == 1 {
            nodes.pop().unwrap()
          } else {
            bail!("There are several nodes with the same properties. Can't deside which one to use. Please use `--id` to specify the exact node");
          }
        } else {
          bail!("node allready exists. Please use `--create-id` to create a node with equal data anyway");
        }
      } else {
        uuid::Uuid::new_v4()
      }
    }
  };

  let mut db = open(&opt.db_path)?;
  if !update {
    db.create_node(Uuid(id), &properties)?;
  } else {
    db.update_node(Uuid(id), &properties)?;
  }

  println!("{}", id); // TODO opt.output, opt.output_fmt
}
----

=== delete_node
Dieses Tool erlaubt einen Knoten aus der Datenbank zu löschen.

[[cmd_options]]
[source, rust]
----
/// delete a node
DeleteNode {
  <<delete_node_args>>
},
----

Dazu übergeben wir die uuid des Knotens.

[[delete_node_args]]
[source, rust]
----
#[clap(long)]
id: uuid::Uuid,
----

[[run_cli_cmds]]
[source, rust]
----
DeleteNode {id} => {
  let mut db = open::<T>(&opt.db_path)?;
  db.delete_node(Uuid(id))?;
  log::info!("deleted node {}", id);
}
----

=== create_edge
Mit diesem Befehl können wir Verbindungen zwischen zwei Knoten schaffen.

[[cmd_options]]
[source, rust]
----
/// create a new edge
CreateEdge {
  <<create_edge_args>>
},
----

Alle Verbindungen sind immer gerichtet. Wir übergeben die id der Knoten `--in` und `--out`.

[[create_edge_args]]
[source, rust]
----
#[clap(long="in")]
n1: uuid::Uuid,
#[clap(long="out")]
n2: uuid::Uuid,
----

[[run_cli_cmds]]
[source, rust]
----
CreateEdge { n1, n2 } => {
  let properties = read_input(opt.input)?;
  let properties: T = SchemaElement::deserialize(&properties)?;

  let mut db = open(&opt.db_path)?;
  let id = db.create_edge(Uuid(n1), Uuid(n2), &properties)?;

  println!("{}", id); // TODO opt.output, opt.output_fmt
}
----

=== delete_edge

=== create_property

TODO Flag List connected properties

=== delete_property

TODO Flag Don't delete from cache
TODO Flag Don't delete connected properties from cache

=== property_id
Diese Funktion ist vor allem für Schema Implementierungen wichtig. Hier kann man Daten übergeben und die Funktion gibt die vom Schema erzeugte Id zurück. Wenn das Schema die Daten als ungültig identifiziert wird mit einer Fehlermeldung abgebrochen.

[[cmd_options]]
[source, rust]
----
/// calculate property id from content
PropertyId,
----

[[run_cli_cmds]]
[source, rust]
----
PropertyId => {
  let properties = read_input(opt.input)?;
  let properties: T = SchemaElement::deserialize(&properties)?;
  let hash = properties.get_key();

  println!("{}", hash); // TODO opt.output, opt.output_fmt
}
----

=== property_blob
Diese Funktion ist ebenfalls vor allem für Schema Implementierungen wichtig. Hier kann man Daten übergeben und die Funktion gibt den vom Schema erzeugten Datenstrom (Blob) zurück. Wenn das Schema die Daten als ungültig identifiziert wird mit einer Fehlermeldung abgebrochen.

[[cmd_options]]
[source, rust]
----
/// create property storage blob from content
PropertyBlob,
----

[[run_cli_cmds]]
[source, rust]
----
PropertyBlob => {
  let properties = read_input(opt.input)?;
  let properties: T = SchemaElement::deserialize(&properties)?;

  io::stdout().write_all(&SchemaElement::serialize(&properties)?)?;
}
----

Um so direkt schreiben zu können, müssen wir zunächst das `Write` Trait importieren.

[[util_imports]]
[source, rust]
----
use std::io::{self, Write};
----

=== query_db
Gibt einen Filter auf die aktuelle Datenbank in der Abfragesprache Zoe (TODO link) zurück.

[[cmd_options]]
[source, rust]
----
/// run a query on the database
QueryDb,
----

TODO Verschiedene Query Sprachen
Zunächst lesen wir die Abfrage ein und dann interpretieren wir sie.

[[run_cli_cmds]]
[source, rust]
----
QueryDb => {
  let query = read_input(opt.input)?;
  let query = to_query(&query)?;

  let db = open::<T>(&opt.db_path)?;
  let result = db.query(query)?;

  <<get_connected_data>>

  // TODO verschiedene output formate
  println!("{}", serde_json::to_string_pretty(&result)?); // TODO wenn kein Terminal sondern eine pipe verwendet wird kann man kompakteres json ausgeben.

  // TODO Umschliessende Huelle? Alle miteinander verbundenen Edges und Vertices?
}
----

Abfragen können in der verschiedensten Form formuliert werden. Wir
verwenden die Zoe (TODO link) Sprache um unsere Abfragen zu definieren.
Allerdings haben wir die Möglichkeit andere Sprachen zu nutzen und diese
in eine gleichwertige Zoe Abfrage umzuwandeln. Dafür müssen wir zunächst
die Sprache importieren.

Anschliessend definieren wir unseren eigenen Dialekt indem wir die
grundlegenden Datentypen festlegen footnote:[Dieser Dialekt wird durch
die Anwendung noch weiter verfeinert, sobald das Schema festgelegt
wird].

[[helper_structs]]
[source, rust]
----
type BasicQuery = gravitydb::kv_graph_store::BasicQuery;
----

Wir gehen davon aus, dass die Abfragen als Json codiert übermittelt werden.

[[helper_structs]]
[source, rust]
----
fn to_query(data: &Vec<u8>) -> Result<BasicQuery, SerialisationError> {
  // TODO Verschiedene Query Sprachen über zweiten Parameter
  // TODO Internes Schema verwenden um Abfragen zu verbessern
  let query = serde_json::from_slice(data)?;

  Ok(query)
}
----

=== repl
Erlaubt die interaktive Manipulation der Datenbank mit einer lua repl.

[[cmd_options]]
[source, rust]
----
/// lua repl for the database
Repl,
----

[[run_cli_cmds]]
[source, rust]
----
Repl => {
  let db = open::<T>(&opt.db_path)?;
  gravitydb::lua::lua_repl::<T, FsKvStore, _, anyhow::Error>(db, init_fn)?;
}
----

[[util_imports]]
[source, rust]
----
use gravitydb::GraphStore;
----

Die konkreten Implementierungen wollen möglicherweise ebenfalls die
Lua Umgebung initialisieren (z.B. um Schema spezifische Anpassungen
vorzunehmen). Deshalb übergeben wir einen Parameter, welche angepasst
werden kann.

[[customize_params]]
[source, rust]
----
init_fn: fn(&mlua::Lua) -> mlua::Result<()>
----

=== script
Führt ein lua Script zur Manipulation der Datenbank aus.

[[cmd_options]]
[source, rust]
----
/// run a lua script
Script,
----

[[run_cli_cmds]]
[source, rust]
----
Script => {
  let path = opt.input.expect("script needs an input parameter");
  let code = std::fs::read_to_string(&path)?;
  let db = open::<T>(&opt.db_path)?;
  gravitydb::lua::lua_run::<T, FsKvStore, _, _ , _>(db, init_fn, code, path.to_string_lossy())?;
}
----

Diese option ist praktisch für batch workloads, wo man viel importieren
oder exportieren will.

Es ist aber auch nützlich für einen alternativen `repl` workflow. Statt
Befehl für Befehl einzugeben und die Ergebnisse anzuschauen kann man
ein ganzes Script eingeben und bei jedem neuen Speichern der Datei
ausführen. Dadurch hat man die Ergebnisse in einem größeren Kontext.

=== result_outer_hull
Das Ergebnis unserer Abfrage ist eine Liste mit Knoten, Verbindungen und weiteren Variablen. Oft möchten wir das weiter ausweiten, indem wir alle Verbindungen zwischen den Knoten ebenfalls anzeigen möchten.

TODO

=== result_inner_hull
Ebenso wie eine umschließende Hülle interessiert uns manchmal eine innere Hülle, bei der wir alle Verbindungen entfernen, die nicht zwischen zwei Knoten der Ergebnismenge liegen.

TODO

=== result_data
Unsere Ergebnisse sind im allgemeinen nur die Ids von Knoten und
Verbindungen aber für die Verarbeitung (und vor allem Darstellung)
interessieren uns viel mehr die Eigenschaften. Mit diesem Befehl
können wir eine Ergebnissmenge nehmen und mit den dazugehörigen Daten
anreichern.

[[cmd_options]]
[source, rust]
----
/// get property data for query result
ResultData,
----

TODO

[[run_cli_cmds]]
[source, rust]
----
ResultData => {
  let data = read_input(opt.input)?;
  //let mut data: crate::ql::QueryResult = serde_json::from_slice(&data)?;

  let db = open::<T>(&opt.db_path)?;
  //TODO Über die db die Variablen im mit den Properties füllen

  // TODO verschiedene output formate
  println!("{}", serde_json::to_string_pretty(&data)?); // TODO wenn kein Terminal sondern eine pipe verwendet wird kann man kompakteres json ausgeben.
}
----


=== db_info
Gibt Informationen über die Datenbank als Json Format aus

* Number of Nodes
* Number of Edges
* Schema Info

=== db_init
Zu Beginn möchte man die Datenbank erstmal initialisieren. Dazu
verwenden wir den Befehl `init`.

[[cmd_options]]
[source, rust]
----
/// initialize a new database
Init,
----

[[run_cli_cmds]]
[source, rust]
----
Init => {
  init::<T>(&opt.db_path)?;
}
----

=== doctor
TODO Dieser Befehl überprüft, ob die Datenbank valid ist und listet Fehler auf.

TODO Fehler im Datei-Baum
TODO Fehler in der Schema Validierung
TODO Fehler in der Schema Validierung der Historie

=== Allgemeines
Natürlich benötigen wir in allen Tools den File Store.

[[util_imports]]
[source, rust]
----
use gravitydb::kv_graph_store::{KvGraphStore, SerialisationError, Uuid};
----

==== Allgemeingültige Kommandozeilen Parameter
Einige Kommandozeilenparameter sind für alle tools nützlich. Wir
verwenden den https://docs.rs/clap/[clap] crate als basis um
die Eingabe zu parsen.

[[util_imports]]
[source, rust]
----
use std::path::{Path, PathBuf};
use clap::Parser;
----

[[cli_parse_cmd_options]]
[source, rust]
----
#[derive(Parser)]
pub struct Opt {
  <<basic_tool_args>>
  #[clap(subcommand)]
  cmd: CmdOpts,
}

#[derive(Parser)]
pub enum CmdOpts {
  <<cmd_options>>
}

let opt = Opt::parse();
simple_logger::init_with_level(log_level(opt.verbosity))?;
----

Es muss immer angegeben werden, wo sich die Datenbank überhaupt
befindet. Falls nichts angegeben wird gehen wir davon aus, dass sie sich
im Unterordner `db` des aktuellen Ordners befindet.

[[basic_tool_args]]
[source, rust]
----
#[clap(long)]
#[clap(default_value = "./db")]
db_path: PathBuf,
----

Normalerweise gibt es eine Eingabedatei die wir einlesen. Wird sie
nicht angegeben geht das Programm davon aus, dass die Daten von `stdin`
eingelesen werden.

[[basic_tool_args]]
[source, rust]
----
#[clap(long, short)]
input: Option<PathBuf>,
----

Genauso ist es mit der Ausgabedatei. Wird sie nicht angegeben, wird auf
`stdout` ausgegeben.

[[basic_tool_args]]
[source, rust]
----
#[clap(long, short)]
output: Option<PathBuf>,
----

Wir benutzen ein Hilfsfunktion um entweder die Daten aus einer Datei zu
lesen oder vom `stdin`.

[[util_imports]]
[source, rust]
----
use std::io::Read;
----

[[tool_helper_functions]]
[source, rust]
----
pub fn read_input(input: Option<PathBuf>) -> Result<Vec<u8>> {
  let data = match input {
    Some(path) => std::fs::read(path)?,
    None => {
      let mut data = Vec::new();
      std::io::stdin().read_to_end(&mut data)?;
      data
    }
  };
  Ok(data)
}
----

TODO Input Format
TODO Output Format
TODO Output File (Default stdout)

Wir wollen logging Informationen über die Kommandozeile anfordern. Je
öfter wir das Flag `v` angeben, desto mehr Daten werden angezeigt.

[[basic_tool_args]]
[source, rust]
----
#[clap(action = clap::ArgAction::Count, short)]
verbosity: u8,
----

[[tool_helper_functions]]
[source, rust]
----
pub fn log_level(level: u8) -> log::Level {
  use log::Level::*;
  match level {
    0 => Warn,
    1 => Info,
    2 => Debug,
    _ => Trace,
  }
}
----

TODO Version information

==== Fehlerbehandlung
Bei den Kommandozeilen Tools möchten wir alle Fehler abfangen. Dazu
verwenden wir die https://docs.rs/anyhow[anyhow] Bibliothek.

[[tool_imports]]
[source, rust]
----
use anyhow::Result;
----

[[util_imports]]
[source, rust]
.Bei den util Funktionen verwenden
----
use anyhow::Result;
----
