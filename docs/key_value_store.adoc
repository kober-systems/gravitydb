= Eine Graphstore-Implementierung für Key-Value Stores

Ein GraphStore kann abstrahiert werden auf einen Store, der auf
beliebigen Key Value Stores aufbaut. Dadurch kann man verschiedene
Implementierungen des KV-Stores als Backends entwickeln welche auf
unterschiedliche Bedürfnisse angepasst werden können.

== Struktur für die Ablage der Daten
Zunächst beschäftigen wir uns mit der Strukturierung der Datenablage um
zu sehen wie unsere Daten aussehen. Anschließend konzentieren wir uns
auf die Funktionen um diese Dateien zu erzeugen und manipulieren.

Ich stelle mir folgende Baumstruktur vor:

[source]
.Dateibaumstruktur der Datenbank
----

db/--+
     +-nodes/--+
     |         +-<uuid>
     |         +-...
     +-edges/--+
     |         +-<hash string>
     |         +-...
     +-props/--+
     |         +-<hash string>
     |         +-...
     +-indexes/--+
     |           +-...
     +-config/--+
     |          +-...
     +-...
----

TODO Implementierung des in memory stores

[%collapsible]
.Beispiel in-Memory Store
====

Bei einer neuen Datenbank erzeugen wir zunächst all diese Ordner.

[[create_db_directories]]
[source, rust]
----
fs::create_dir_all(&path.join("nodes/"))?;
fs::create_dir_all(&path.join("edges/"))?;
fs::create_dir_all(&path.join("props/"))?;
fs::create_dir_all(&path.join("indexes/"))?;
----

Wird eine bestehende Datenbank geöffnet muss überprüft werden, ob die
entsprechenden Ordner vorhanden sind.

[[check_db_directories]]
[source, rust]
----
if !&path.join("nodes/").is_dir() ||
  !&path.join("edges/").is_dir() ||
  !&path.join("props/").is_dir() ||
  !&path.join("indexes/").is_dir() {
    return Err(Error::MalformedDB);
}
----

Falls die Struktur nicht eingehalten wurde geben wir einen Fehler aus.

[[errors]]
[source, rust]
----
#[error("wrongly formatted database: {0}")]
MalformedDB(String),
----

====

Innerhalb dieser Ordner (oder der meisten dieser Ordner denn z.B. config
enthält ja nur Beschreibungsdaten) werden die Datensätze als Dateien
abgelegt. Der Dateiname ist dabei der Schlüssel mit dem man auf die
Daten zugreift und der Dateiinhalt ist der Wert. Als Schlüssel wird
entweder ein `Hash` oder eine `Uuid` verwendet.

Hash:: Ein
  https://en.wikipedia.org/wiki/Cryptographic_hash_function[Hash]
  ist die eindeutige Zusammenfassung des Inhalts als eine
  Zahl. Alles was einen `hash` als Schlüssel hat ist somit ein
  https://en.wikipedia.org/wiki/Content-addressable_storage[content
  addressable store] da mit dem Schlüssel der Inhalt fest verbunden ist.
  Der verwendete Hash Algorithmus kann über die Konfiguration festgelegt
  werden. Das hat ein paar Vorteile:
** Die Daten können nur entweder erstellt oder gelöscht werden aber
   nicht verändert. Daraus ergeben sich eine Menge Möglichkeiten für die
   Synchronisierung und Prüfung der Datenintegrität.
Uuid:: Eine
  https://en.wikipedia.org/wiki/Universally_unique_identifier[Uuid]
  ist eine eindeutige Id bei der nicht die Gefahr besteht, das zwei
  unterschiedliche Prozesse die gleiche id erstellen (nicht mal wenn
  die Prozesse auf unabhängigen und nicht miteinander kommunizierenden
  Computern ablaufen). Datensätze welche eine `uuid` als Schlüssel
  verwenden können modifiziert werden.

Wie wir später noch sehen werden hat diese Strukturierung Vorteile um
die Daten gut <<sync, synchronisieren>> und effektiv durchsuchen zu
können.

Um diese Keys umzusetzen verwenden wir die https://docs.rs/uuid[uuid]
und https://docs.rs/sha2[sha2] crates. Für sie definieren wir eine
Hilfsschnittstelle, um die Umwandlung in einen Datenbankschlüssel zu
erlauben.

[[helper_functions]]
[source, rust]
----
fn uuid_to_key(id: uuid::Uuid) -> String {
  id
    .hyphenated()
    .encode_lower(&mut uuid::Uuid::encode_buffer())
    .to_string()
}
----

Als Schlüssel betrachten wir hier den zusammengefassten Dateinamen
aus allen Ordnernamen unterhalb der hier aufgeführten Struktur und
dem Dateinamen (ohne die Trennzeichen wie z.B `/`). Wie viele Ordner
verwendet werden sollen und ob die Tiefe dynamisch angepasst werden
soll hängt von der Konfiguration ab. Dadurch ist es möglich die
Abfragegeschwindigkeiten zu optimieren je nachdem wie voll die Datenbank
ist.

Dateinamen sind im Grunde Strings, weshalb wir unsere Hashes in diesem
Fall als String definieren können.

[[structs]]
[source, rust]
----
type HashId = String;
----

Als Hash Funktion nutzen wir (vorerst) sha256. Dafür importieren wir die
Digest traits.

[[imports]]
[source, rust]
----
use sha2::Digest;
----

=== Die einzelnen Datentypen
Nun wollen wir die Einzelheiten und Schemata der einzelnen Datentypen
besprechen.

Die Dateiinhalte sind Key-Value Stores welche die Werte das Datensatzes
enthalten. Man kann dafür z.B. Json, messagepack oder etwas anderes
verwenden (theoretisch könnte man sogar wieder das Datesystem verwenden,
da ein Ordner ja auch nichts anderes als ein Key-Value-Store ist). Das
verwendete Dateiformat kann über die Konfiguration festgelegt werden
(das Schema dagegen besprechen wir in den folgenden Abschnitten). Zu
Beginn mag es nützlich sein Json zu verwenden, da es leicht zum Debuggen
geeignet ist.

Um uns die Flexibilität zu erhalten verwenden wir zunächst
https://serde.rs/[serde] zur Serialisierung. Dadurch lässt sich das
Datenformat für unsere Datentypen leicht austauschen. Natürlich kann man
als Properties (TODO link) beliebige Dateien und Formate abspeichern.

Zu Beginn nutzen wir json als Serialisierungsformat footnote:[Das gilt
nur für unsere internen Datenstrukturen innerhalb der Datenbank. Jedes
Schema kann völlig frei seine eigene Serialisierung wählen]. Dazu nutzen
wir `serde_json`.

Wir verwenden die Schema Traits (TODO link) von gravity um die
Datentypen zu definieren. Dadurch haben wir später die Möglichkeit
zum validieren (TODO link) und optimieren (TODO link), was gerade bei
Transaktionen (TODO link) von großem Nutzen ist.

[[imports]]
[source, rust]
----
use crate::schema::SchemaElement;
----

=== Knoten (nodes)
Der Ordner `nodes` enthält die Knoten (oder Vertices). Diese sind für mich der Einstiegspunkt in die Daten (wenn ich eine Suche beginne ist das in den meisten Fällen mit einem Knoten. Manchmal möchte ich auch eine Property abfragen, doch dafür durchsuche ich entweder den gesamten Store (wenn die Abfrage etwas außergewöhniches ist) oder ich lege einen Index an (und indexe sind wieder Knoten).

Eine Knoten Datei hat folgendes Schema:

[source, json]
----
{
  "uuid": uint64,
  "props": uint64,
  "edges": {
    "in": [ uint64, uint64, ... ],
    "out": [ uint64, uint64, ... ],
  }
}
----

[[imports]]
[source, rust]
----
use serde::{Serialize, Deserialize};
use std::collections::{BTreeSet, HashMap, HashSet};
----

[[schema_structs]]
[source, rust]
----
#[derive(Deserialize, Serialize, Debug)]
pub struct NodeData {
  pub id: uuid::Uuid,
  // Schlüssel des Datensatzes, welcher die Eigenschaften
  // des Knotens enthält
  pub properties: HashId,
  // Hashes der eingehenden Verbindungen (Edges)
  pub incoming: BTreeSet<HashId>,
  // Hashes der ausgehenden Verbindungen (Edges)
  pub outgoing: BTreeSet<HashId>,
}

impl SchemaElement<String, SerialisationError> for NodeData
{
  fn get_key(&self) -> String {
    uuid_to_key(self.id)
  }

  fn serialize(&self) -> Result<Vec<u8>, SerialisationError> {
    Ok(serde_json::to_vec(self)?)
  }

  fn deserialize(data: &[u8]) -> Result<Self, SerialisationError>
  where
    Self: Sized,
  {
    Ok(serde_json::from_slice(data)?)
  }
}
----

Die `uuid` ist ja der Key und somit im Dateinamen enthalten. Es
könnte aber interessant sein um Überprüfungen vorzunehmen und so z.B.
reagieren zu können falls eine Datei umbenannt wurde oder bei einer
Synchronisierung falsch übertragen wurde.

Der Hash bei `props` ist ein Verweis auf den jeweiligen Datensatz im
entsprechenden store.

TODO Eventuell kann durch die Konfiguration ein etwas anderes Schema unterhalb von `edges` festgelegt werden. Das würde helfen sobald man eine Menge Verbindungen zwischen den einzelnen Knoten hätte und hängt somit stark von der Füllung der Datenbank ab, als auch von der Struktur der Daten selbst.

=== Verbindungen (edges)
Im Ordner `edges` werden die Verbindungen (oder Edges, Relationships,
Links) gespeichert. Sie haben folgendes Schema:

[source, json]
----
{
  "props": uint64,
  "in": uint64,
  "out": uint64
}
----

[[schema_structs]]
[source, rust]
----
#[derive(Deserialize, Serialize, Debug)]
pub struct EdgeData {
  pub properties: HashId,
  pub n1: uuid::Uuid,
  pub n2: uuid::Uuid,
}

impl SchemaElement<HashId, SerialisationError> for EdgeData
{
  fn get_key(&self) -> HashId {
    let data = serde_json::to_vec(self).unwrap();
    format!("{:X}", sha2::Sha256::digest(&data))
  }

  fn serialize(&self) -> Result<Vec<u8>, SerialisationError> {
    Ok(serde_json::to_vec(self)?)
  }

  fn deserialize(data: &[u8]) -> Result<Self, SerialisationError>
  where
    Self: Sized,
  {
    Ok(serde_json::from_slice(data)?)
  }
}
----

`props` ist wieder ein Verweis auf den Eintrag im entsprechenden Store.

Die Datenbank lässt nur gerichtete Verbindungen zu.

`in` bezieht sich auf die uuid vom eingehenden Knoten.

`out` bezieht sich auf die uuid vom ausgehenden Knoten.

=== Eigenschaften (properties)
Im Ordner `properties` können beliebige Daten gespeichert werden. Diese
Dateien enthalten das, was man im Allgemeinen als die eigentlichen
Nutzdaten betrachten würde.

In einem herkömmlichen Arbeitsprozess (also ohne Graphendatenbank)
sind alle Dateien die man erzeugt und bearbeitet mit Properties
gleichzusetzen. Und in einer SQL Datenbank entspräche der Inhalt aller
Zeilen, die keine Primary- oder Foreign-Keys enthalten, den Properties.

Dementsprechend ist es sinnvoll für jede Anwendung ein eigenes Schema
(TODO link) für die Properties zu entwerfen und benutzen (ähnlich wie
man es bei einer SQL Datenbank auch tun würde).

Daten die man hier verwendet können beliebige Inhalte haben. Es
wäre aber klug (wenn auch nicht erforderlich) zu versuchen nicht
deterministische Daten wie Änderungszeitstempel (oder Zeitstempel
allgemein) vor dem Abspeichern aus den Dateien zu entfernen. Tut man das
nicht, kann der nicht-Determinismus die Synchronisiation stark belasten.
Es wäre also gut zu überdenken ob man einen direkten Anwendungsfall für
die Auswertung solcher veränderlichen Daten hat oder die Daten sich sehr
selten verändern, bevor man sich entschließt nicht deterministische
Daten abzuspeichern.

=== Indexe und Garbarge-Collection
Wenn wir Elemente löschen, ergibt sich die Aufgabe, dass wir eventuell
verbundene Elemente mitlöschen müssen wenn kein Verweis mehr darauf
existiert. Dazu legen wir eine zweite Ordnerstruktur (im Ordner
`indexes` TODO eventuell sollten wir einen Unterordner von `indexes`
verwenden um weitere unsichtbare Verweistypen zu ermöglichen) an.
Diese enthält redundante Daten, die aber dafür schnellere Zugriffe
ermöglichen.

Eine Alternative dazu wäre garbarge-collection als einen eigenen Befehl
zu implementieren, der manuell aufgerufen werden müsste. Dies hätte
den Nachteil, dass dafür immer die gesamte Datenbank durchsucht werden
müsste. Andererseits wären Daten, die oft gelöscht und wieder angelegt
werden weiter im Cache und dadurch würden einige Schreibaktionen weniger
Aufwand verursachen.

Ein Vorteil der automatisch gepflegten Indexe für die
Garbarge-Collection ist, dass sie gleichzeitig eine deutlich schnellere
Suche nach Knoten oder Verbindungen deren Eigenschaften (Properties)
bekannt sind, ermöglichen. Dafür gibt es sehr viele Anwendungsfälle.

==== Struktur des Indexes
Wir legen alle Properties als Ordner an. In diesen Ordnern befinden
sich jeweils alle darauf verweisenden Elemente (egal ob Node, Edge oder
Property) als Links.

----
indexes/--+
          +-<property-hash>-+
          |                 +-props_<hash> # -> db/indexes/<linking-property-hash>
          |                 +-nodes_<uuid> # -> db/nodes/<uuid>
          |                 +-...
          +-<linking-property-hash>-+
          |                         +-...
          +-...
----

Da wir also recht häufig einen entsprechenden Link anlegen müssen
verwenden wir dafür eine Hilfsfunktion.

Als Parameter übergeben wir unter anderem die Art des Backlinks (node,
edge oder property). Daraus läßt sich einerseits der Pfad ermitteln und
andererseits erleichtert man das <<process_property_query, Filtern>>,
indem man den Namen anhängt (z.B. node_<uuid> oder edge_<hashid>).

[[structs]]
[source, rust]
----
enum BacklinkType {
  Node,
  Edge,
  Property,
}
----

[[kv_graph_store_functions]]
[source, rust]
----
/// props_hash: the hash_id of the property that holds the index
/// id:         the id of the node, edge or property that references
///             the property and needs a backling
/// ty:         the type of the element that needs a backlink
fn create_idx_backlink(&mut self, props_hash: &str, id: &str, ty: BacklinkType) -> Result<(), Error<E>> {
  let index_path = "indexes/".to_string() + props_hash + "/";
  self.kv.create_bucket(index_path.as_bytes()).map_err(|e| Error::KV(e))?;

  let prefix = match ty {
    BacklinkType::Node => "nodes",
    BacklinkType::Edge => "edges",
    BacklinkType::Property => "props",
  };
  let backlink_path = index_path + prefix + "_" + id;
  let path = prefix.to_string() + "/" + id;
  self.kv.store_record(&backlink_path.as_bytes(), &path.as_bytes()).map_err(|e| Error::KV(e))?;

  Ok(())
}
----

Zudem haben wir eine Funktion um die links wieder zu löschen. Ist keine
weitere Referenz vorhanden wird auch die Eigenschaft aus dem Store
gelöscht.

[[kv_graph_store_functions]]
[source, rust]
----
fn delete_property_backlink(&mut self, props_hash: &str, id: &str, ty: BacklinkType) -> Result<bool, Error<E>> {
  let index_path = "indexes/".to_string() + props_hash + "/";

  let prefix = match ty {
    BacklinkType::Node => "nodes",
    BacklinkType::Edge => "edges",
    BacklinkType::Property => "props",
  };
  let backlink_path = index_path.clone() + prefix + "_" + id;
  self.kv.delete_record(backlink_path.as_bytes()).map_err(|e| Error::KV(e))?;

  if self.kv.list_records(index_path.as_bytes()).map_err(|e| Error::KV(e))?.is_empty() {
    Ok(true)
  } else {
    Ok(false)
  }
}
----

==== Suche nach Properties
Durch den zuvor beschriebenen Index ergibt sich eine besondere
Möglichkeit nach Eigenschaften zu suchen.

Will man zum Beispiel nach Einträgen suchen, die sich auf den Begriff
"Suche" beziehen könnte man folgendermaßen vorgehen:

. Man erstellt den Datensatz footnote:[Der Datensatz und das Format
  hängen vom Schema ab. Das ist nicht Teil dieses Dokumentes sondern
  muss separat definiert werden. Dieser Datastore ist in der Lage mit
  beliebigen Schemata umzugehen.]
+
[source, json]
----
{ "concept": { "name": "Suche" } }
----

. Man erzeugt den hash. Dazu kann es nötig sein, den Datensatz zu
  sortieren, komprimieren und verändern (z.B. nur Kleinbuchstaben) um
  auch wirklich sicher den gleichen Hash zu bekommen.
+
[source, sh]
----
hash=`sha256sum < ${dataset}`
----

. Man gibt den Hash ein und ließt die verweisenden Daten aus
+
[source, sh]
----
ls db/indexes/${hash}
----

[[wal_transactions]]
== Write-Ahed-Log
Wenn man die Daten in der Datenbank manipuliert ist es wichtig, dass
die Datenbank nicht unbrauchbar wird oder kapput geht wenn irgend etwas
schief geht. Man spricht hier von atomaren Opterationen die entweder
als ganzes funktionieren oder abgebrochen werden aber die Anwendung
nicht in einem Zwischenzustand zurücklassen. Zu diesem Zweck hat man
https://en.wikipedia.org/wiki/Database_transaction[Transaktionen]
erdacht footnote:[Weitere Informationen sind
unter https://en.wikipedia.org/wiki/ACID und
https://en.wikipedia.org/wiki/Transaction_log und
https://en.wikipedia.org/wiki/Shadow_paging und
https://sqlite.org/wal.html Ich bin mir nicht ganz sicher, ob die hier
von mir beschriebene Technik wirklich Write-Ahead-logging ist, oder ob
es sich eher um Shadow-Paging handelt].

Wir versuchen das Problem folgendermaßen zu lösen:

Zunächst arbeiten wir mit zwei Kopien der Datenbank (da einige Bereiche
mit hashes addressiert werden und daher content addressable stores sind)
können wir hier Hart-Links (TODO linK) verwenden.

Auf der Hauptebene haben wir dann eine Datei welche als Information
enthält welcher der beiden stores gerade der aktuelle ist (zum lesen.
Dieser muss immer valid sein) und welcher Prozess auf den anderen Store
zum schreiben zugreift (kann auch leer also kein Prozess sein).

Will ein Prozess zum schreiben zugreifen so muss er zuerst eine Datei
anlegen, welche zeigt das er gerade den Zugriff hat und dann diese Datei
verschieben, so dass sie den offiziellen Zeiger ersezt (verschieben von
Dateien ist eine atomare Operation und kann daher nicht aus Versehen
unterbrochen werden).

Dann kann er den Store bearbeiten. Sobald er fertig ist geht er mit der
gelichen Technik wie am Anfang vor um zu zeigen, das nun der andere
Store der valide Lese-Store ist.

TODO Natürlich brauchen wir auch eine Möglichkeit damit die lesenden Prozesse anzeigen können, dass sie gerade lesen und daher kein schreibender Prozess zugreifen kann bevor sie mit lesen fertig sind. Eventuell kann man hier bei Bedarf die Stores beliebig oft kopieren um lange Lesezugriffe zuzulassen ohne den Schreibzugriff dauerhaft zu blockieren (könnte man als eine Art Thread Pool betrachten wenn auch sicher die Technik an sich ganz anders funktioniert).

[[sync]]
== Synchronisierung
Dies dürfte eins der Killer-Features dieses Stores sein. Man
könnte bestehende vcs-Systeme wie https://git-scm.com/[git] oder
https://pijul.org/[pijul] verwenden um die Daten zu synchronisieren (und
zwar asynchron und verteilt).

Die Vorgehensweise dazu ist folgende:

Immer wenn eine Transaktion abgeschlossen ist (siehe
<<wal_transactions>>) wird zunächst ein prozess ausgeführt, dem alle
Änderungen übergeben werden. Konkret heist das:

* Welche Knoten angelegt wurden
* Welche Knoten verändert wurden
** z.B. andere Properties oder andere edges
* Welche Knoten gelöscht wurden
** zudem alle damit verbundenen Edges da diese alle mit gelöscht wurden
* Welche Edges angelegt wurden
* Welche Edges gelöscht wurden
* Bei welchen Edges die Properties verändert wurden
** Das entspricht dem löschen der alten Edge und dem anlegen einer neuen
   Edge
* Auf welche Properties neu verwiesen wird
** recursiv falls Properties auf properties verweisen
* Auf welche Properties niemand mehr verweist
** recursiv falls Properties auf properties verweisen

Aus diesen Informationen macht man dann einen Commit (oder die jeweilige Entsprechung in einem anderen vcs System).

[[schema_structs]]
[source, rust]
----
pub struct Change {
  pub created: ChangeSet,
  pub modified: BTreeSet<NodeChange>,
  pub deleted: ChangeSet,
  pub depends_on: BTreeSet<HashId>, // <1>
}

pub struct NodeChange {
  pub id: uuid::Uuid,
  pub properties: HashId,
}

pub struct ChangeSet {
  pub nodes: BTreeSet<NodeChange>,
  pub edges: BTreeSet<EdgeData>,
  //pub properties: BTreeSet<Property>,
}
----
<1> Zusätzlich zu den eigentlichen Änderungen haben wir auch eine Liste
    der vorhergehenden `Change` Einträge, von denen dieser Change
    abhängig ist. Das macht es uns bei der Synchronisierung leichter
    zwischen Konflickten und problemlosen Zusammenführungen zu
    unterscheiden.

Wenn wir zusätzlich einen guten Diff Mechanismus bereitstellen (und da
wir die Datenstruktur gut kennen könnten wir das wahrscheinlich tun)
könnten wir dem Benutzer eine sehr komfortable Umgebung bereitstellen um
Konflikte zu lösen.

Beim Synchronisieren (mergen) könnten wir Algorithmen zur Verfügung
stellen welche Ähnlichkeiten zwischen neu angelegten Datensätzen
aufzeigen (z.B. wenn ein neuer Knoten teilweise übereistimmende Edges
hat und ein Teil seiner Property Werte ähnlich ist). Dadurch könnte man
schnell erkennen, dass man an verschiedenen Stellen das gleiche Ziel
hatte (wenn man es auch nicht identisch umgesetzt hat). So kann man
frühzeitig solche Datensätze wieder zu einem zusammenführen oder aber
erkennen, dass man sie klarer voneinander abgrenzen muss oder sehen,
dass es eine andere interessierte Partei gibt (welche einem bis dahin
vielleicht unbekannt war) und das man sich absprechen sollte.

== Sharding
Sharding ist das aufteilen der Datenbank in kleinere Subdatenbanken
welche aber miteinander verbunden sein können. Das wäre ebenfalls ein
Killer-Feature, weil es ermöglichen würde kleinere Teile der Datenbank
zu lagern und somit mit kleinen Geräten (wie Handys) den für sie
relevanten Teil der Datenbank zu verwalten und damit bei Bedarf offline
zu arbeiten und gleichzeitig eine große Datenbank zu haben welche
übergreifende Analysen und/oder rechenintensive Operationen durchführt.
Außerdem erlaubt es die Synchronisation all dieser kleinen Datenbanken
(welche ja mitunter nicht den gleichen Ausschnitt der Gesamtdaten
enthalten). Eine weitere Anwendung wäre sicherheitskritische Daten
abzutrennen und dennoch im sync mit den normalen Operationsdaten zu
halten.

Allerdings stellt uns das ganze vor einige schwierige Herausforderungen.
Es ist sehr schwer zu entscheiden welcher Datensatz welcher
Datenpartition zugeordnent werden soll. Was ist mit Verbindungen
zwischen zwei Partitionen?

TODO Beschreibung der Probleme, möglicher Lösungen (sowohl algoritmisch als auch manuell), der Konfiguration und der Auswirkungen auf die Dateistruktur und die nötigen Anpassungen an den <<sync, Synchronisierungsmechnismen>>.

== Implementierung

=== CRUD Funktionen
Wir benötigen natürlich zunächst die allgemeinenen Funktionen für eine
Datenbank.

In unserer Datenbank gibt es drei grundlegende Typen: Nodes, Edges und
Properties.

[[graph_store_functions]]
[source, rust]
.Funktionen für Knoten
----
fn create_node(&mut self, id: uuid::Uuid, properties: &P) -> Result<uuid::Uuid, Error<E>> {
  <<create_node>>
  let props_hash = self.create_property(properties)?;
  let node = NodeData {
    id,
    properties: props_hash.clone(),
    incoming: BTreeSet::new(),
    outgoing: BTreeSet::new(),
  };
  let key = node.get_key();
  let node = SchemaElement::serialize(&node)?;

  let path = "nodes/".to_string() + &key;

  <<check_if_node_exists_allready>>

  <<write_node>>
  self.kv.store_record(&path.as_bytes(), &node).map_err(|e| Error::KV(e))?;

  self.create_idx_backlink(&props_hash, &key, BacklinkType::Node)?;

  Ok(id)
}

fn read_node(&self, id: uuid::Uuid) -> Result<NodeData, Error<E>> {
  let path = "nodes/".to_string() + &uuid_to_key(id);

  let data = self.kv.fetch_record(path.as_bytes()).map_err(|e| Error::KV(e))?;
  let node: NodeData = SchemaElement::deserialize(&data)?;
  Ok(node)
}

fn update_node(&mut self, id: uuid::Uuid, properties: &P) -> Result<uuid::Uuid, Error<E>> {
  <<create_new_property>>
  let props_hash = self.create_property(properties)?;
  <<update_node_data>>
  let path = "nodes/".to_string() + &uuid_to_key(id);
  let NodeData {
    id,
    properties: old_properties,
    incoming,
    outgoing,
  } = self.read_node(id)?;
  let node = NodeData {
    id,
    properties: props_hash.clone(),
    incoming,
    outgoing,
  };
  let node = SchemaElement::serialize(&node)?;
  self.kv.store_record(&path.as_bytes(), &node).map_err(|e| Error::KV(e))?;

  let key = uuid_to_key(id);
  let last_reference = self.delete_property_backlink(&old_properties, &key, BacklinkType::Node)?;
  if last_reference {
    self.delete_property(&old_properties)?;
  }

  self.create_idx_backlink(&props_hash, &key, BacklinkType::Node)?;

  Ok(id)
}

fn delete_node(&mut self, id: uuid::Uuid) -> Result<uuid::Uuid, Error<E>> {
  let NodeData {
    id,
    properties,
    incoming: _,
    outgoing: _,
  } = self.read_node(id)?;

  let key = uuid_to_key(id);
  let path = "nodes/".to_string() + &key;

  let last_reference = self.delete_property_backlink(&properties, &key, BacklinkType::Node)?;
  if last_reference {
    self.delete_property(&properties)?;
  }

  self.kv.delete_record(path.as_bytes()).map_err(|e| Error::KV(e))?;
  Ok(id)
}
----

Wenn bereits ein Knoten mit entsprechender ID existiert kann er nicht
erzeugt werden (höchstens aktualisiert).

[[check_if_node_exists_allready]]
[source, rust]
----
if self.kv.exists(path.as_bytes()).map_err(|e| Error::KV(e))? {
  return Err(Error::NodeExists(path));
};
----

[[errors]]
[source, rust]
----
#[error("node {0} allready exists")]
NodeExists(String),
----

[[graph_store_functions]]
[source, rust]
.Funktionen für Verbindungen
----
fn create_edge(&mut self, n1: uuid::Uuid, n2: uuid::Uuid, properties: &P) -> Result<HashId, Error<E>> {
  let props_hash = self.create_property(properties)?;
  let edge = EdgeData {
    n1,
    n2,
    properties: props_hash.clone(),
  };

  let hash = edge.get_key();
  let path = "edges/".to_string() + &hash;

  let edge = SchemaElement::serialize(&edge)?;
  self.kv.store_record(&path.as_bytes(), &edge).map_err(|e| Error::KV(e))?;

  self.create_idx_backlink(&props_hash, &hash, BacklinkType::Edge)?;

  let path = "nodes/".to_string() + &uuid_to_key(n1);
  let NodeData {
    id,
    properties,
    incoming,
    mut outgoing,
  } = self.read_node(n1)?;
  outgoing.insert(hash.clone());
  let node = NodeData {
    id,
    properties,
    incoming,
    outgoing,
  };
  let node = SchemaElement::serialize(&node)?;
  self.kv.store_record(&path.as_bytes(), &node).map_err(|e| Error::KV(e))?;

  let path = "nodes/".to_string() + &uuid_to_key(n2);
  let NodeData {
    id,
    properties,
    mut incoming,
    outgoing,
  } = self.read_node(n2)?;
  incoming.insert(hash.clone());
  let node = NodeData {
    id,
    properties,
    incoming,
    outgoing,
  };
  let node = SchemaElement::serialize(&node)?;
  self.kv.store_record(&path.as_bytes(), &node).map_err(|e| Error::KV(e))?;

  Ok(hash)
}

fn read_edge(&self, id: &HashId) -> Result<EdgeData, Error<E>> {
  let path = "edges/".to_string() + id;

  let data = self.kv.fetch_record(path.as_bytes()).map_err(|e| Error::KV(e))?;
  let edge = SchemaElement::deserialize(&data)?;
  Ok(edge)
}

fn delete_edge(&mut self, id: &HashId) -> Result<(), Error<E>> {
  let EdgeData {
    properties: props_hash,
    n1,
    n2,
  } = self.read_edge(id)?;

  let path = "edges/".to_string() + id;

  self.kv.delete_record(&path.as_bytes()).map_err(|e| Error::KV(e))?;

  let path = "nodes/".to_string() + &uuid_to_key(n1);
  let NodeData {
    id: _id,
    properties,
    incoming,
    mut outgoing,
  } = self.read_node(n1)?;
  outgoing.remove(id);
  let node = NodeData {
    id: n1,
    properties,
    incoming,
    outgoing,
  };
  let node = SchemaElement::serialize(&node)?;
  self.kv.store_record(&path.as_bytes(), &node).map_err(|e| Error::KV(e))?;

  let path = "nodes/".to_string() + &uuid_to_key(n2);
  let NodeData {
    id: _id,
    properties,
    mut incoming,
    outgoing,
  } = self.read_node(n2)?;
  incoming.remove(id);
  let node = NodeData {
    id: n2,
    properties,
    incoming,
    outgoing,
  };
  let node = SchemaElement::serialize(&node)?;
  self.kv.store_record(&path.as_bytes(), &node).map_err(|e| Error::KV(e))?;

  let last_reference = self.delete_property_backlink(&props_hash, &id, BacklinkType::Edge)?;
  if last_reference {
    self.delete_property(&props_hash)?;
  }

  Ok(())
}
----

[[serialisation_errors]]
[source, rust]
----
#[error("json error")]
Json { #[from] source: serde_json::Error },
----

[[graph_store_functions]]
[source, rust]
.Eigenschaften speichern
----
fn create_property(&mut self, properties: &P) -> Result<HashId, Error<E>> {
  let hash = properties.get_key();
  let path = "props/".to_string() + &hash;

  let data = properties.serialize()?;
  self.kv.store_record(&path.as_bytes(), &data).map_err(|e| Error::KV(e))?;

  <<store_nested_properties>>

  Ok(hash)
}
----

Da Eigenschaften in einer Baumstruktur angelegt werden können (TODO Link
aufs Schema) wollen wir, dass auch alle zugehörigen Datensätze abgelegt
werden (mit anderen Worten: Die Funktion soll rekursiv aufgerufen
werden). Hier kann es schnell vorkommen, dass Datensätze bereits
verwendet wurden (und deshalb bereits gespeichert sind). Das betrachten
wir nicht als Fehler.

[[store_nested_properties]]
[source, rust]
----
properties.nested().iter().try_for_each(|nested| {
  match self.create_property(nested) {
    Ok(nested_hash) => {
      self.create_idx_backlink(&nested_hash, &hash, BacklinkType::Property)?;
      Ok(())
    }
    Err(e) => {
      use Error::*;
      match e {
        ExistedBefore => Ok(()),
        _ => Err(e),
      }
    }
  }
})?;
----

[[graph_store_functions]]
[source, rust]
.Eigenschaften auslesen
----
fn read_property(&self, id: &HashId) -> Result<P, Error<E>> {
  let path = "props/".to_string() + id;

  let data = self.kv.fetch_record(path.as_bytes()).map_err(|e| Error::KV(e))?;
  let property = SchemaElement::deserialize(&data)?;
  Ok(property)
}
----

[[graph_store_functions]]
[source, rust]
.Eigenschaften aus der Datenbank löschen
----
fn delete_property(&mut self, id: &HashId) -> Result<(), Error<E>> {
  let path = "props/".to_string() + id;

  <<delete_nested_properties>>

  self.kv.delete_record(path.as_bytes()).map_err(|e| Error::KV(e))?;
  Ok(())
}
----

Wenn wir Eigenschaften löschen müssen wir natürlich auch die Indexe von
allen Eigenschaften löschen, die auf sie verweisen.

[[delete_nested_properties]]
[source, rust]
----
let data = self.kv.fetch_record(&path.as_bytes()).map_err(|e| Error::KV(e))?;
let properties: P = SchemaElement::deserialize(&data)?;

for nested in properties.nested().iter() {
  let nested_hash = nested.get_key();
  let last_reference = self.delete_property_backlink(&nested_hash, id, BacklinkType::Property)?;
  if last_reference {
    self.delete_property(&nested_hash)?;
  }
}
----

TODO Überprüfen, ob noch Knoten oder Verbindungen auf eine Eigenschaft verweisen. In diesem Fall darf sie nicht gelöscht werden.

=== Die allgemeine Schnittstelle
Die vorigen CRUD Funktionen haben ein sehr niedriges Level. Die Benutzer
der Datenbank sollen allgemeinere Funktionen nutzen können. Dazu
implementieren wir die Schnittstellen der Gravity Graphen API (TODO
link).

[[imports]]
[source, rust]
----
use crate::GraphStore;
----

[[interface_implementations]]
[source, rust]
----
impl<P, K, E> GraphStore<uuid::Uuid, NodeData, HashId, EdgeData, HashId, P, Error<E>> for KvGraphStore<P, K, E>
where
  P: Property<HashId, SerialisationError>,
  K: KVStore<E>,
  E: Send,
{
  <<graph_store_functions|join="\n\n">>
}
----

[[imports]]
[source, rust]
----
use crate::GraphBuilder;
----

[[interface_implementations]]
[source, rust]
----
impl<N, P, K, E> GraphBuilder<N, P, Error<E>> for KvGraphStore<P, K, E>
where
  N: Node<P>,
  P: Property<HashId, SerialisationError>,
  K: KVStore<E>,
  E: Send,
{
  fn add_node(&mut self, node: N) -> Result<(), Error<E>> {
    let p = node.properties();
    self.create_node(node.id(), &p)?;
    Ok(())
  }

  fn add_edge(&mut self, n1: &N, n2: &N, p: &P) -> Result<(), Error<E>> {
    self.create_edge(n1.id(), n2.id(), p)?;
    Ok(())
  }

  fn remove_node(&mut self, node: &N) -> Result<(), Error<E>> {
    self.delete_node(node.id())?;
    Ok(())
  }

  fn remove_edge(&mut self, n1: &N, n2: &N, p: &P) -> Result<(), Error<E>> {
    let props_hash = p.get_key();
    let edge = EdgeData {
      n1: n1.id(),
      n2: n2.id(),
      properties: props_hash,
    };

    self.delete_edge(&edge.get_key())?;
    Ok(())
  }
}
----

=== Schema Schnittstellen für Knoten, Verbindungen und Eigenschaften
Unsere Datenbank erlaubt es ein Schema zu definieren. Damit das möglich
ist müssen die einzelnen Elemente Schnittstellen bereitstellen.

[[imports]]
[source, rust]
----
use crate::schema::Property;
----

[[traits]]
[source, rust]
----
pub trait Node<P: Property<HashId, SerialisationError>> {
  fn id(&self) -> uuid::Uuid;
  fn properties(&self) -> P;
}
----

[[errors]]
[source, rust]
----
#[error("the element existed before")]
ExistedBefore,
----

=== Abfrage Sprache einlesen
Abfragen können in der verschiedensten Form formuliert werden. Wir
verwenden die Zoe (TODO link) Sprache um unsere Abfragen zu definieren.
Allerdings haben wir die Möglichkeit andere Sprachen zu nutzen und diese
in eine gleichwertige Zoe Abfrage umzuwandeln. Dafür müssen wir zunächst
die Sprache importieren.

[[imports]]
[source, rust]
----
use crate::ql;
----

Anschliessend definieren wir unseren eigenen Dialekt indem wir die
grundlegenden Datentypen festlegen footnote:[Dieser Dialekt wird durch
die Anwendung noch weiter verfeinert, sobald das Schema festgelegt
wird].

[[structs]]
[source, rust]
----
type BasicQuery = ql::BasicQuery<uuid::Uuid, HashId, HashId, ql::ShellFilter, ql::ShellFilter>;
type QueryResult = ql::QueryResult<uuid::Uuid, HashId>;
----

Wir gehen davon aus, dass die Abfragen als Json codiert übermittelt
werden.

[[helper_functions]]
[source, rust]
----
pub fn to_query(data: &Vec<u8>) -> Result<BasicQuery, SerialisationError> {
  // TODO Verschiedene Query Sprachen über zweiten Parameter
  // TODO Internes Schema verwenden um Abfragen zu verbessern
  let query = serde_json::from_slice(data)?;

  Ok(query)
}
----

Das eigentlich Interessante an einer Datenbank sind natürlich die
Abfragen selbst. Daher wollen wir uns als nächstes damit beschäftigen,
wie wir aus der Abfrage an die Daten in der Datenbank kommen.

[[fs_store_functions]]
[source, rust]
----
pub fn query<Q: Into<BasicQuery>>(&self, q: Q) -> Result<QueryResult, Error<E>> {
  let q = q.into();
  let context = match q {
    BasicQuery::V(q) => {
      self.query_nodes(q)?.into()
    }
    BasicQuery::E(q) => {
      self.query_edges(q)?.into()
    }
    BasicQuery::P(q) => {
      self.query_property_nodes(q)?.into()
    }
  };

  Ok(context)
}
----

Nachdem man eine Abfrage gemacht hat, erhält man als Ergebnis ein
`QueryResult`. Im Grunde genommen kann man das als eine Art Subgraphen
betrachten. Ein häufiger Anwendungsfall ist, das man sich lediglich für
die Properties aller im Result enthaltenen daten interessiert. Dafür
stellen wir eine Funktion bereit.

[[fs_store_functions]]
[source, rust]
----
pub fn extract_properties(&self, result: &QueryResult) -> Result<Vec<T>, Error<E>> {
  let nodes_iter = result.vertices.iter().map(|n_id| {
    let n = self.read_node(*n_id)?;
    self.read_property(&n.properties)
  });
  let edges_iter = result.edges.iter().map(|e_id| {
    let e = self.read_edge(&e_id)?;
    self.read_property(&e.properties)
  });
  nodes_iter.chain(edges_iter).collect::<Result<Vec<T>,_>>()
}
----

Manchmal interessiert einen der Lösungsweg mehr als die Lösung selbst.
Dafür werden die Lösungspfade im Abfrageergebnis gespeichert. Wenn man
diese anylysiert will man manchmal einfach die Properties durchgehen.
Dazu stellen wir eine Hilfsfunktion bereit.

[[fs_store_functions]]
[source, rust]
----
pub fn extract_path_properties(&self, result: &QueryResult) -> Result<Vec<Vec<T>>, Error<E>> {
  result.paths.iter()
    .map(|(start, path, end)| {
      path.into_iter()
        .fold(Ok(vec![]), |path, (v_id, e_id)| {
          let mut path: Vec<_> = path?;
          let n = self.read_node(*v_id)?;
          let prop = self.read_property(&n.properties)?;
          path.push(prop);

          let e = self.read_edge(e_id)?;
          let prop = self.read_property(&e.properties)?;
          path.push(prop);

          if let Some(e_id) = start {
            let e = self.read_edge(e_id)?;
            let prop = self.read_property(&e.properties)?;
            path.insert(0, prop);
          }
          if let Some(v_id) = end {
            let n = self.read_node(*v_id)?;
            let prop = self.read_property(&n.properties)?;
            path.push(prop);
          }

          Ok(path)
        })
    })
    .collect::<Result<Vec<Vec<_>>, _>>()
}
----

=== Abfragen verarbeiten
Alle unsere Abfragen arbeiten mit einem Startpunkt. Von diesem
Startpunkt aus arbeiten wir uns vorwärts indem wir bei allen
angrenzenden Elementen (Bei Knoten Verbindungen und umgekehrt)
überprüfen, ob sie die Bedingungen erfüllen. Falls ja, nehmen wir das
aktuelle Element in den Pfad, den unsere Abfrage bis jetzt genommen hat,
mit auf und übernehmen das angrenzende Element als neuen Startpunkt.

Das bedeutet also, dass wir als Ergebniswerte unserer Abfrageschritte,
eine Liste aller angrenzenden Elemente (die die Filterkriterien
erfüllen) und die jeweils zu ihnen hinführenden Pfade bekommen.

[[structs]]
[source, rust]
.Ergebnistypen eines Abfrageschrittes
----
type NodeCtx = HashMap<uuid::Uuid, ql::VertexQueryContext<uuid::Uuid, HashId>>;
type EdgeCtx = HashMap<HashId, ql::EdgeQueryContext<uuid::Uuid, HashId>>;
----

Unsere Funktionen bekommen demnach eine Abfrage übergeben und geben eine
entsprechende Ergebnismenge zurück.

[[fs_store_functions]]
[source, rust]
----
fn query_nodes(
  &self,
  q: ql::VertexQuery<uuid::Uuid, HashId, HashId, ql::ShellFilter, ql::ShellFilter>
) -> Result<NodeCtx, Error<E>> {
  use ql::VertexQuery::*;

  let result = match q {
    <<process_vertex_query>>
  };

  Ok(result)
}

fn query_edges(
  &self,
  q: ql::EdgeQuery<uuid::Uuid, HashId, HashId, ql::ShellFilter, ql::ShellFilter>,
) -> Result<EdgeCtx, Error<E>> {
  use ql::EdgeQuery::*;

  let result = match q {
    <<process_edge_query>>
  };

  Ok(result)
}
----

[[fs_store_functions]]
[source, rust]
----
fn query_property_nodes(
  &self,
  q: ql::PropertyQuery<HashId>
) -> Result<NodeCtx, Error<E>> {
  let mut result = HashMap::default();

  let properties = self.query_properties(q)?;
  // TODO Wie bei ReferencedProperties properties aber Verweise auf Knoten herausfiltern

  Ok(result)
}
----

Bei den Abfragen auf Eigenschaften ist es ganz ähnlich. Allerdings
verwenden wir sie ganz am Anfang (z.B. um Startpunkte zu finden). Daher
haben wir hier noch keinen Pfad zu dem Punkt den wir dem Abfrageschritt
mit übergeben müssten (Es ist ja der allererste Schritt).

[[fs_store_functions]]
[source, rust]
----
fn query_properties(
  &self,
  q: ql::PropertyQuery<HashId>
) -> Result<HashSet<HashId>, Error<E>> {
  use ql::PropertyQuery::*;

  let mut result = HashSet::default();

  match q {
    <<process_property_query>>
  };

  Ok(result)
}
----

==== Abfragen auf Knoten
Alle Knoten abzufragen ist einfach. Wir müssen einfach nur alle Einträge
im `db/nodes/` Ordner (TODO link) auflisten.

[[process_vertex_query]]
[source, rust]
----
All => {
  self.kv.list_records("nodes/".as_bytes())
    .map_err(|e| Error::KV(e))?
    .into_iter()
    .map(|entry| {
      let id = String::from_utf8(entry)?;
      let id = uuid::Uuid::parse_str(&id)?;
      Ok((id, ql::VertexQueryContext::new(id)))
  })
  .collect::<Result<HashMap<_,_>, Error<E>>>()?
}
----

[[errors]]
[source, rust]
----
#[error("wrongly formatted input: {0}")]
MalformedInput(#[from] std::string::FromUtf8Error),
#[error("uuid parsing error (corrupted db)")]
Uuid { #[from] source: uuid::Error },
----

Bei einer Abfrage auf alle Verbindungen ist es ähnlich (nur das wir hier
den Ordner `edges` auflisten).

[[process_edge_query]]
[source, rust]
----
All => {
  self.kv.list_records("edges/".as_bytes())
    .map_err(|e| Error::KV(e))?
    .into_iter()
    .map(|entry| {
      let id = String::from_utf8(entry)?;
      let key = id.clone();
      Ok((id, ql::EdgeQueryContext::new(key)))
  })
  .collect::<Result<HashMap<_,_>, Error<E>>>()?
}
----

Ist bereits eine id angegeben müssen wir sie nur die bestehenden durch
sie ersetzen.

[[process_vertex_query]]
[source, rust]
----
Specific(ids) => {
  ids.into_iter()
    .map(|id| (id, ql::VertexQueryContext::new(id)))
    .collect()
}
----

[[process_edge_query]]
[source, rust]
----
Specific(ids) => {
  ids.into_iter()
    .map(|id| (id.clone(), ql::EdgeQueryContext::new(id)))
    .collect()
}
----

Suchen wir nach einer bestimmten Eigenschaft müssen wir zunächst den
Filter dort ansätzen. Dann suchen wir nach Links zu Knoten (TODO link)
die auf diese Eigenschaften verweisen.

[[process_property_query]]
[source, rust]
----
Specific(id) => {
  let path = "props/".to_string() + &id;
  if self.kv.exists(path.as_bytes())
    .map_err(|e| Error::KV(e))?
  {
    result.insert(id);
  }
}
ReferencingProperties(q) => {
  for prop_id in self.query_properties(*q)? {
    let index_path = "indexes/".to_string() + &prop_id + "/";
    for entry in self.kv.list_records(index_path.as_bytes()).map_err(|e| Error::KV(e))? {
      let reference = String::from_utf8(entry)?;
      let (prefix, reference) = reference
        .split_once("_")
        .ok_or(Error::MalformedDB(format!("could not split {} (prefix : {})", reference, index_path)))?;
      if prefix == "props" {
        result.insert(reference.to_string());
      }
    }
  }
}
ReferencedProperties(q) => {
  // TODO Hier benötigen wir das Schema
}
----

Bei Knoten und Verbindungen deren die auf eine Eigenschaft verweisen ist
es ganz ähnlich. Wir verwenden zunächst die Suche nach Eigenschaften um
Start-Eigenschaften zu finden und suchen dann alle verweisenden Knoten
mit dem Prefix `nodes` heraus.

[[process_vertex_query]]
[source, rust]
----
Property(q) => {
  let mut result = HashMap::default();

  for prop_id in self.query_properties(q)? {
    let index_path = "indexes/".to_string() + &prop_id + "/";
    for entry in self.kv.list_records(index_path.as_bytes()).map_err(|e| Error::KV(e))? {
      let reference = String::from_utf8(entry)?;
      let (prefix, reference) = reference
        .split_once("_")
        .ok_or(Error::MalformedDB(format!("could not split {} (prefix : {})", reference, index_path)))?;
      if prefix == "nodes" {
        let id = uuid::Uuid::parse_str(reference)?;
        result.insert(id, ql::VertexQueryContext::new(id));
      }
    }
  }

  result
}
----

Bzw bei Verbindungen mit dem Prefix `edges`.

[[process_edge_query]]
[source, rust]
----
Property(q) => {
  let mut result = HashMap::default();

  for prop_id in self.query_properties(q)? {
    let index_path = "indexes/".to_string() + &prop_id + "/";
    for entry in self.kv.list_records(index_path.as_bytes()).map_err(|e| Error::KV(e))? {
      let reference = String::from_utf8(entry)?;
      let (prefix, reference) = reference
        .split_once("_")
        .ok_or(Error::MalformedDB(format!("could not split {} (prefix : {})", reference, index_path)))?;
      if prefix == "edges" {
        let id = reference.to_string();
        let key = id.clone();
        result.insert(id, ql::EdgeQueryContext::new(key));
      }
    }
  }

  result
}
----

Beim Union Befehl werden die Ergebnisse alle Queries zusammengefasst.
Wir führen also alle Abfragen aus und vereinigen dann alle Ergebnisse zu
einem großen Ergebnis.

TODO Paralell ausführen

[[process_vertex_query]]
[source, rust]
----
Union(sub1, sub2) => {
  union(
    self.query_nodes(*sub1)?,
    self.query_nodes(*sub2)?
  )
}
----

[[process_edge_query]]
[source, rust]
----
Union(sub1, sub2) => {
  union(
    self.query_edges(*sub1)?,
    self.query_edges(*sub2)?
  )
}
----

Um die Kontexte zu vereinigen benutzen wir eine Hilfsfunktion.

TODO Wahrscheinlich ist die Struktur für den Kontext nicht korrekt. So ist es z.B. nicht möglich mehrere Pfade nebeneinander abzuspeichern.

[[helper_functions]]
[source, rust]
----
fn union<K, V>(
  c1: HashMap<K, V>,
  c2: HashMap<K, V>
) ->
  HashMap<K, V>
where
  K: Eq + Hash,
{
  let mut result = c1;

  result.extend(c2.into_iter());
  result
}
----

[[imports]]
[source, rust]
----
use core::hash::Hash;
----

Bei einer Intersection übernehmen wir nur die Ergebnisse, wo die Knoten
in allen Unterabfragen vorhanden sind.

TODO Wir wollen alle Pfade entfernen, die zu einem Knoten gehören, der nicht von beiden Abfragen erfasst wird.

[[process_vertex_query]]
[source, rust]
----
Intersect(sub1, sub2) => {
  intersection(
    self.query_nodes(*sub1)?,
    self.query_nodes(*sub2)?,
  )
}
----

[[process_edge_query]]
[source, rust]
----
Intersect(sub1, sub2) => {
  intersection(
    self.query_edges(*sub1)?,
    self.query_edges(*sub2)?,
  )
}
----

[[helper_functions]]
[source, rust]
----
fn intersection<K, V>(
  c1: HashMap<K, V>,
  c2: HashMap<K, V>
) ->
  HashMap<K, V>
where
  K: Eq + Hash,
{
  let mut result = c1;
  let mut c2 = c2;

  c2.retain(|k, _v| result.contains_key(k));
  result.retain(|k, _v| c2.contains_key(k));
  result
}
----

Bei der Substract Aktion werden alle Ergebnisse der zweiten Abfrage von
der ersten abgezogen.

[[process_vertex_query]]
[source, rust]
----
Substract(sub1, sub2) => {
  substraction(
    self.query_nodes(*sub1)?,
    self.query_nodes(*sub2)?
  )
}
----

[[process_edge_query]]
[source, rust]
----
Substract(sub1, sub2) => {
  substraction(
    self.query_edges(*sub1)?,
    self.query_edges(*sub2)?
  )
}
----

[[helper_functions]]
[source, rust]
----
fn substraction<K, V>(
  c1: HashMap<K, V>,
  c2: HashMap<K, V>
) ->
  HashMap<K, V>
where
  K: Eq + Hash,
{
  let mut result = c1;

  result
    .retain(|k, _v| !c2.contains_key(k));

  result
}
----

`DisjunctiveUnion` Aktionen übernehmen alle Knoten, die von der einen oder der anderen Abfrage erfasst wurden aber nicht von beiden.

[[process_vertex_query]]
[source, rust]
----
DisjunctiveUnion(sub1, sub2) => {
  disjunction(
    self.query_nodes(*sub1)?,
    self.query_nodes(*sub2)?
  )
}
----

[[process_edge_query]]
[source, rust]
----
DisjunctiveUnion(sub1, sub2) => {
  disjunction(
    self.query_edges(*sub1)?,
    self.query_edges(*sub2)?
  )
}
----

[[helper_functions]]
[source, rust]
----
fn disjunction<K, V>(
  c1: HashMap<K, V>,
  c2: HashMap<K, V>
) ->
  HashMap<K, V>
where
  K: Eq + Hash + Clone,
  V: Clone,
{
  let mut result = HashMap::default();

  result.extend(c1.clone().into_iter().filter(|(k, _)| c2.contains_key(k)));
  result.extend(c2.into_iter().filter(|(k, _)| c1.contains_key(k)));

  result
}
----

Die `Store` Aktion ist eigentlich eine Kurzschreibweise für eine `Union`
der aktuell erfassten Knoten und der nachfolgenden Abfragen.

Es wird bereits ein Kontext benötigt, um ihn abspeichern zu können.
Daher kann `Store` nicht zu Beginn einer Abfragekette kommen.

[[process_vertex_query]]
[source, rust]
----
Store(_q) => unreachable!(),
----

[[process_edge_query]]
[source, rust]
----
Store(_q) => unreachable!(),
----

Bei `In` und `Out` hangelt man sich zu benachbarten Verbindungen durch.
Dazu muss bereits ein Startpunkt vorhanden sein.

[[process_vertex_query]]
[source, rust]
----
Out(q) => {
  self.query_edges(q)?.into_iter()
    .map(|(edge_id, ctx)| {
      let edge = self.read_edge(&edge_id)?;
      Ok((edge.n2, ctx.into_vertex_ctx(edge.n2)))
    })
    .collect::<Result<HashMap<_,_>, Error<E>>>()?
}
In(q) => {
  self.query_edges(q)?.into_iter()
    .map(|(edge_id, ctx)| {
      let edge = self.read_edge(&edge_id)?;
      Ok((edge.n1, ctx.into_vertex_ctx(edge.n1)))
    })
    .collect::<Result<HashMap<_,_>, Error<E>>>()?
}
----

[[process_edge_query]]
[source, rust]
----
Out(q) => {
  let context = self.query_nodes(*q)?;

  let mut result = HashMap::default();

  for (node_id, ctx) in context.into_iter() {
    let node = self.read_node(node_id)?;
    for edge_id in node.outgoing.into_iter() {
      let key = edge_id.clone();
      result.insert(edge_id, ctx.clone().into_edge_ctx(key));
    }
  }

  result
}
In(q) => {
  let context = self.query_nodes(*q)?;

  let mut result = HashMap::default();

  for (node_id, ctx) in context.into_iter() {
    let node = self.read_node(node_id)?;
    for edge_id in node.incoming.into_iter() {
      let key = edge_id.clone();
      result.insert(edge_id, ctx.clone().into_edge_ctx(key));
    }
  }

  result
}
----

TODO Die übrigen beschreiben

[[process_vertex_query]]
[source, rust]
----
Filter(_q, _filter) => unreachable!(),
----

[[process_edge_query]]
[source, rust]
----
Filter(_q, _filter) => unreachable!(),
----

[[process_chain_vertex_query]]
[source, rust]
----
Filter(_q, _filter) => {
  HashMap::default()
  // TODO
}
----

=== Abfragen optimieren
TODO

=== Dateiorganisation des Crates
Wie überall benötigt man einiges an Boilerplate-Code.

[source, rust, save]
.src/kv_graph_store.rs
----
<<imports>>

<<traits|join="\n\n">>

<<structs|join="\n\n">>

<<interface_implementations|join="\n\n">>

<<schema_structs|join="\n\n">>

<<helper_functions|join="\n\n">>
----

Die wichtigste Struktur ist natürlich der Store selbst.

[[structs]]
[source, rust]
----
pub struct KvGraphStore<T, K, E>
where
  T: Property<HashId, SerialisationError>,
  K: KVStore<E>,
  E: Send,
{
  kv: K,
  <<kv_graph_store_vars>>
}

impl<T, K, E> KvGraphStore<T, K, E>
where
  T: Property<HashId, SerialisationError>,
  K: KVStore<E>,
  E: Send,
{
  <<fs_store_functions|join="\n\n">>
  <<kv_graph_store_functions|join="\n\n">>
}
----

Dieser Store bekommt einen `KVStore` übergeben, welcher für die
eigentliche Datenspeicherng verantwortlich ist.

[[imports]]
[source, rust]
----
use crate::KVStore;
----

Um die Type-Constraints der möglichen Implementierungen sichern zu
können, müssen wir `PhantomData` als Trick benutzen. Dadurch werden
Variablen angelegt, welche nur zur Compile-Zeit bestehen. Diese können
wir nutzen um die notwendigen Constraints zu definieren.

[[imports]]
[source, rust]
----
use std::marker::PhantomData;
----

[[kv_graph_store_vars]]
[source, rust]
----
p_marker: PhantomData<T>,
kv_err_marker: PhantomData<E>,
----

Um die eigentliche Arbeit des Ablegens der Daten kümmert sich der
zugrunde liegende Key-Value-Store. Um unsere Graphendatenbank zu
erzeugen verwenden wir eine Funktion, welcher der Key-Value-Store
übergeben wird.

[[fs_store_functions]]
[source, rust]
----
pub fn from_kv(kv: K) -> Self {
  KvGraphStore {
    p_marker: PhantomData,
    kv_err_marker: PhantomData,
    kv,
  }
}
----

Für Test-Zwecke wollen wir zudem von Zeit zu Zeit direkt auf den
Key-Value-Store zugreifen. Deshalb erstellen wir auch dafür eine
Funktion.

[[fs_store_functions]]
[source, rust]
----
pub fn into_kv(self) -> K {
  self.kv
}
----

==== Fehlerbehandlung
Wir verwenden den https://docs.rs/thiserror/1.0.26/thiserror/[thiserror]
crate um die Fehlerbehandlung zu implementieren.

[[imports]]
[source, rust]
----
use thiserror::Error;
----

[[structs]]
[source, rust]
----
#[derive(Error, Debug)]
pub enum Error<E: Send> {
  <<errors>>
  #[error("problem with kv store")]
  KV(E),
  #[error(transparent)]
  Prop(#[from] SerialisationError),
}

#[derive(Error, Debug)]
pub enum SerialisationError {
  <<serialisation_errors>>
}
----

=== Lua Bindings
Manchmal ist es praktisch eine interaktive Sprache zur Verfügung zu
haben um schneller experimentieren zu können. Dazu implementieren wir
eine Anbindung an lua. Das erlaubt die interaktive Manipulation der
Datenbank mit einer lua repl.

Der Ablauf ist wie bei jeder anderen repl auch:

* Wir lesen das Script soweit ein, wie möglich
* Dann für wir das eingelesene Statement des Scripts aus
** Kommt es zu Fehlern untersuchen wir ob das Script noch nicht
   vollständig ist, oder ob wir die Verarbeitung abbrechen müssen.
* Wir formatieren die Ausgabe und geben sie für den Benutzer aus.
* Und dann kehren wir zum Anfang zurück (lesen das nächste Statement des
  Scripts ein).

[[run_lua_repl]]
[source, rust]
----
use mlua::{Error, MultiValue};
use rustyline::{Editor, error::ReadlineError};

let lua = Lua::new();
let mut editor = Editor::<LuaCompleter, rustyline::history::DefaultHistory>::new().expect("Failed to make rustyline editor");
editor.set_helper(Some(LuaCompleter { lua: &lua }));

<<init_lua_environment>>

loop {
  let mut prompt = "> ";
  let mut line = String::new();

  loop {
    let input = match editor.readline(prompt) {
      Ok(out) => Ok(out),
      Err(ReadlineError::Eof) => return Ok(()),
      Err(e) => Err(e),
    }?;
    line.push_str(&input);

    match lua.load(&line).eval::<MultiValue>() {
      Ok(values) => {
        editor.add_history_entry(line)?;
        println!(
          "{}",
          values
            .iter()
            .map(|value| format!("{:?}", value))
            .collect::<Vec<_>>()
            .join("\t")
        );
        break;
      }
      Err(Error::SyntaxError {
        incomplete_input: true,
        ..
      }) => {
        // continue reading input and append it to `line`
        line.push_str("\n"); // separate input lines
        prompt = ">> ";
      }
      Err(e) => {
        eprintln!("error: {}", e);
        break;
      }
    }
  }
}
----

Damit man mit der Repl auch etwas anfangen kann, muss sie auch
Funktionen bieten um die Datenbank zu manipulieren. Dazu binden wir den
`FsStore` Typ in unsere Lua Umgebung ein:

[[interface_implementations]]
[source, rust]
----
#[cfg(feature="lua")]
impl<P, K, E> UserData for KvGraphStore<P, K, E>
where
  for<'lua> P: Property<HashId, SerialisationError> + UserData + std::clone::Clone + 'lua + FromLua<'lua>,
  K: KVStore<E>,
  E: Send + Sync + std::fmt::Debug,
{
  fn add_methods<'lua, M: UserDataMethods<'lua, Self>>(methods: &mut M) {
    use mlua::prelude::LuaError;

    methods.add_method_mut("create_node", |_, db, props: P| {
      let id = uuid::Uuid::new_v4();
      match db.create_node(id, &props) {
        Ok(_) => Ok(()),
        Err(e) => Err(LuaError::external(e.to_string()))
      }
    });
  }
}
----

Und wir benötigen einige Constructor Funktionen um die Datenbank
verfügbar zu machen.

[[init_lua_environment]]
[source, rust]
----
let globals = lua.globals();
globals.raw_set("db", db)?;
----

Zudem laden wir die Funktionen der Abfragesprache Zoe (TODO link) in
unsere Lua Umgebung.

[[init_lua_environment]]
[source, rust]
----
ql::init_lua::<String, HashId, HashId, String, String>(&lua)?; // <1>
----
<1> Die generischen Parameter besetzen wir mit den in der Db
    hardverdrahteten Id Typen

Die konkreten Implementierungen wollen möglicherweise ebenfalls die
Lua Umgebung initialisieren (z.B. um Schema spezifische Anpassungen
vorzunehmen). Deshalb übergeben wir einen Parameter, welche angepasst
werden kann.

[[customize_params]]
[source, rust]
----
init_fn: fn(&Lua) -> mlua::Result<()>
----

[[init_lua_environment]]
[source, rust]
----
init_fn(&lua)?;
----

Um besser mit der Repl arbeiten zu können stellen wir dem User eine
Autovervollständigung zur Verfügung.

[[lua_repl_completer]]
[source, rust]
----
#[cfg(feature="lua")]
use rustyline::{completion::Completer, Helper, Hinter, Validator, Highlighter};

#[cfg(feature="lua")]
#[derive(Helper, Hinter, Validator, Highlighter)]
struct LuaCompleter<'a> { lua: &'a Lua }

#[cfg(feature="lua")]
impl Completer for LuaCompleter<'_> {
  type Candidate = String;
  fn complete(
          &self,
          line: &str,
          pos: usize,
          _ctx: &rustyline::Context<'_>
  ) -> rustyline::Result<(usize, Vec<Self::Candidate>)> {
    let mut completetions = vec![];

    let line = &line[..pos];
    let bounderies = [' ', '\t', '(', ')', '[', ']', '{', '}'];
    let start = line.rfind(&bounderies).unwrap_or(0);
    let tokens = &line[start..].split(&['.', ':']);
    let level_cnt = tokens.clone().count();

    use mlua::Value::*;

    tokens.clone().fold((1, Table(self.lua.globals())), |(level, v), t| {
      let t = t.trim_start_matches(&bounderies);
      if let Table(ref v) = v {
        if level == level_cnt {
          v.for_each(|k: mlua::Value, _v: mlua::Value| {
              if let Ok(k) = k.to_string() {
                if k.starts_with(t) {
                  completetions.push(k[t.len()..].to_string());
                }
            };

            Ok(())
          }).unwrap_or_default();
        } else {
          return (level + 1, match v.raw_get(t) {
            Ok(v) => {
              v
            }
            Err(_) => {
              Nil
            }
          });
        }
      }

      (level + 1, v)
    });

    Ok((pos, completetions))
  }
}
----

[[interface_implementations]]
[source, rust]
----
<<lua_repl_completer>>

#[cfg(feature="lua")]
pub fn lua_repl<T, Kv, E, OutE>(db: KvGraphStore<T, Kv, E>, init_fn: fn(&Lua) -> mlua::Result<()>) -> Result<(), OutE>
where
  for<'lua> T: Property<HashId, SerialisationError> + 'lua + FromLua<'lua> + UserData + Clone,
  Kv: KVStore<E> + 'static,
  E: Send + Sync + std::fmt::Debug + 'static,
  OutE: From<rustyline::error::ReadlineError> + From<mlua::Error>,
{
  <<run_lua_repl>>
}
----


[[imports]]
[source, rust]
----
#[cfg(feature="lua")]
use mlua::{Lua, FromLua, UserData, UserDataMethods};
----

